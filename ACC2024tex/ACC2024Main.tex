%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8

\documentclass[letterpaper, 10 pt, conference]{ieeeconf}  % Comment this line out
                                                          % if you need a4paper
%\documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4
                                                          % paper

\IEEEoverridecommandlockouts                              % This command is only
                                                          % needed if you want to
                                                          % use the \thanks command
\overrideIEEEmargins
% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document



% The following packages can be found on http:\\www.ctan.org
\usepackage{graphics} % for pdf, bitmapped graphics files
\usepackage{epsfig} % for postscript graphics files
 \usepackage{mathptmx} % assumes new font selection scheme installed
% \usepackage{times} % assumes new font selection scheme installed
\usepackage{amsmath} % assumes amsmath package installed
\usepackage{amssymb}  % assumes amsmath package installed
\usepackage{subfigure}
\usepackage{xcolor}

\newcommand{\usequence}[2]{(u_{i,t})_{i=1,t=1}^{#1,#2}}
\newcommand{\contTilde}[1]{\mathbf{\tilde{#1}}}
\newcommand{\transpose}{\mathsf{T}}
\newcommand{\myinner}[1]{\langle(#1)x,x\rangle}
\newcommand{\quadinner}[1]{x^{\transpose}(#1)x}
\DeclareMathOperator{\contB}{\mathbf{B}}
\DeclareMathOperator{\Log}{\mathrm{Log}}
\newcommand{\BK}[1]{\mathbf{B}\bar{K}_{#1}}
%bound \| x_t - x_{t|t} \|
\newcommand{\boundxtxtgt}[2]{C_{fb}^{2}\|\bar{x}_{1}\|[\frac{C_{K}}{\gamma-1}\bigg(\frac{1-(\eta\gamma)^{#1}}{1-\eta\gamma} - \frac{1-\eta^{#1}}{1-\eta} \bigg){#2}+\varepsilon_{K}\bigg(\frac{(#1-1)\eta^{#1+1}-#1\eta^{#1}+\eta}{(1-\eta)^{2}}\bigg)]}
\DeclareMathOperator{\tempRBP}{R + B^{\transpose}PB}
\DeclareMathOperator{\Nplayers}{\{1,2,\cdots,\textit{N}\}}
\DeclareMathOperator{\Rgame}{\bar{R}}
\DeclareMathOperator{\Qgame}{\bar{Q}}
\DeclareMathOperator{\Pgame}{\bar{P}}
\DeclareMathOperator{\Kgame}{\bar{K}}
\DeclareMathOperator{\Timelen}{\mathbb{N}_{T-1}}
\newcommand{\RBPGame}[1]{\Rgame_{#1 -1}+\contB^{\transpose}\Pgame_{#1}\contB}

% \newcommand{\boundxtxtgt1}[1]{\frac{#1}{2}}
%bound |K_t|t - K_t^*|
\newcommand{\boundKt}{C_{K^{'}}\gamma^{W-1} + \gamma_{K^{'}}}

%bound xt|t
\newcommand{\boundxtgt}[1]{C_{fb}\eta^{#1}}

% \newcommand{\\det}{\mathit{\det}}
% \newcommand{\Log}[1]{\text{Log}}

\newtheorem{problem}{Problem}
\newtheorem{lemma}{Lemma}
\newtheorem{assumption}{Assumption}
\newtheorem{definition}{Definition}
\newtheorem{corollary}{Corollary}
\newtheorem{proposition}{Proposition}
\newtheorem{remark}{Remark}
\newtheorem{theorem}{Theorem}

\title{\LARGE \bf
Online Linear-Quadratic Feedback Potential Dynamic Games:\\ An Algorithm and Regret Analysis
}

%\author{ \parbox{3 in}{\centering Huibert Kwakernaak*
%         \thanks{*Use the $\backslash$thanks command to put information here}\\
%         Faculty of Electrical Engineering, Mathematics and Computer Science\\
%         University of Twente\\
%         7500 AE Enschede, The Netherlands\\
%         {\tt\small h.kwakernaak@autsubmit.com}}
%         \hspace*{ 0.5 in}
%         \parbox{3 in}{ \centering Pradeep Misra**
%         \thanks{**The footnote marks may be inserted manually}\\
%        Department of Electrical Engineering \\
%         Wright State University\\
%         Dayton, OH 45435, USA\\
%         {\tt\small pmisra@cs.wright.edu}}
%}

\author{Yitian Chen, Timothy Molloy, Iman Shames% <-this % stops a space
}
\allowdisplaybreaks


\begin{document}



\maketitle
\thispagestyle{empty}
\pagestyle{empty}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
We investigate a new online linear-quadratic feedback potential dynamic game problem in which players in a potential dynamic game with time-varying quadratic costs have the cost matrices revealed to them sequentially, with the potential for future values to be previewed over a short window.
We propose and analyse an algorithm that enables the players to predict a Nash equilibrium and track towards it.
We adopted the notion of \emph{dynamic social regret} to measure the performance of this proposed method, with our main result being that the dynamic social regret of our method is upper bounded by a constant. Moreover, the regret is upper bounded by a sum of two terms; one that decays exponentially as the preview horizon grows, and another that depends on the distance between cost matrices for each player. 
We demonstrate through simulations that the resulting dynamic social regret initially decays at a faster-than-exponential rate with the preview window length, and then remains almost constant for large time horizons.
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{INTRODUCTION}
% \begin{enumerate}
%     \item Introduce Dynamic games
%     \item potential examples of online dynamic game
%     \item Introduce optimal control online
% \end{enumerate}

Noncooperative dynamic game theory is a mathematical framework for decision-making among rational players that interact through a dynamical system  \cite{basar_dynamic_1998,engwerda_lq_2005}. It has proven invaluable in modelling complex scenarios involving multiple agents, such as optimising network resources in contexts like multichannel communication and resource allocation \cite{prasad_structure_2023,zazo_dynamic_2016}.
The vast majority of noncooperative dynamic games are formulated assuming that the players engage in competitive interactions with complete knowledge of all players' costs.
However, in many practical situations, the costs that players could incur are unknown in advance.
For example, consider two users sending messages through a shared relay. Each message sent from the users consumes the relay's battery. 
The costs to the users are associated with the relay's battery level (with the users both attempting to keep the battery at some nominal charge) and the amount of data they transmit. 
Unpredictable environmental conditions such as variations in temperature, humidity and latency, modify the battery's charge and hence the associated cost.
Similarly, the communication system's operator may vary the cost associated with data transmission to manage the network.
In this paper, we pose and investigate a new online dynamic game problem where costs are time-varying and unknown in advance.

%Additionally, unpredictable communication conditions such as variation in temperature, humidity and latency, can be modelled as time-varying costs. However, real-word complexity often limits access to future transmission costs. 

%Each player incurs time-varying costs that hinge on both the present state and the decisions of all participants.



% For example, consider two distributors that can choose the quantity of goods to supply to a collection of stores. All goods are transported to a packaging store before arriving at the grocery stores. They attempt to minimizes their transportation costs whilst maximizing their utilities from goods.
% The state at any given time encapsulates the amount of packages from the packaging company. Meanwhile, the decisions involve determining how much food each distributor (indexed as $i$) should dispatch to the stores. These decisions come with associated costs, for instance, profit and product availability are contingent on the states and choices made.
%For example, consider food delivery from distributors to grocery stores. The state at any given time encapsulates information about inventory levels at a distributor warehouse. Meanwhile, the decisions involve determining how much food each distributor (indexed as $i$) should dispatch to the stores. These decisions come with associated costs, for instance, profit and product availability are contingent on the states and choices made.

%However, real-world complexity often limits access to comprehensive future profit and product availability data for specific goods. Therefore, we cannot assume we have access to full information for all costs over a given period. In this context, we frame the problem as a dynamic game. At each time step, a player makes a decision based on the available cost information that can be accessed. This setup is referred to as an online dynamic game. The performance of each player is gauged by quantifying the discrepancy between the current decision and its Nash Equilibrium when all cost information is revealed to all players. In the Nash Equilibrium, each player's strategy is optimal when considering the decisions of other players. This paper aims at identifying the classes of dynamic games, referred to as \emph{potential dynamic games}, where the Nash Equilibrium can be obtained by solving a single optimal control problem.
%Each player incurs time-varying costs that hinge on both the present state and the decisions of all participants.


% {\color{red} 2nd paragraph should cite and discuss partial info games - say something like ``partial state information has been considered previously, however, to the best of our knowledge uncertain costs have not been.''}

 %* Dynamic games in partial state information have been considered previously { \color{red} still need this?}. 

Similar investigations of online repeated games (without state dynamics) have recently been conducted in \cite{lu_online_2021,meng_decentralized_2022} and reviewed in \cite{li_survey_2023}. In these works, players have no knowledge of the cost functions of other players, and their own costs at the current time (and time-varying constraints) will be revealed after decisions are made. To the best of our knowledge, there has been no work on online dynamic game problems that have the additional complexity of the game having a persistent dynamic state.

%, which generalized online optimal control from one decision-maker (or player) to multiple, potentially competing decision-makers.

The lack of consideration of online noncooperative dynamic game problems appears in part due to the difficulty of finding (feedback) Nash equilibria in general noncooperative dynamic games.
Computing Nash equilibria in noncooperative dynamic games inherently can be viewed as the problem of solving multiple coupled optimal control problems, which is difficult even if all costs are known \emph{a priori} \cite{basar_dynamic_1998,engwerda_lq_2005}. 
{\color{red} Most recently, \emph{Potential Dynamic Games} have been explored in \cite{gonzalez-sanchez_discretetime_2013,jewaidu_rilwan_potential_2021}}.
Feedback Nash equilibria in dynamic potential games can be found by solving multivariate optimal control problems. 
Under certain conditions pertaining to system dynamics and cost functions, the optimal solution aligns with the concept of a feedback Nash equilibrium \cite[Section 4]{monderer_potential_1996}. 
Consequently, potential dynamic games can be seen as natural extensions of optimal control, introducing multiple players into the dynamic interaction \cite{prasad_structure_2023}. Motivated by the unexplored problem of online dynamic games and the recent breakthroughs in linear-quadratic (LQ) potential games, in this paper, we propose and analyse an algorithm for solving the online LQ feedback potential game problem.

The key contributions of this paper are:
\begin{enumerate}
    \item The formulation of a novel online LQ feedback potential dynamic game problem with a \emph{dynamic social regret} performance measure;
    \item The proposal of an algorithm that enables players to predict and track a Nash equilibrium in an online LQ feedback potential dynamic game;
    \item An upper bound on the dynamic social regret achieved by our proposed algorithm.
\end{enumerate}
There are similar results and algorithms that are available for online LQ optimal control problems \cite{abbasi-yadkori_regret_2011,chen_regret_2023,zhang_regret_2021}. 
We specifically introduce and use dynamic social regret as our notion of regret to capture the discrepancy (in the hindsight) between the decisions made by players using our proposed algorithm, and a Nash equilibrium solution found with access to full cost information.

This paper is structured as follows.
In Section \ref{sec:problem_formulation}, we formulate the online LQ feedback potential game problem. In Section \ref{sec:approach}, we present our proposed algorithm and an upperbound on its performance measured by dynamic social regret. In Section \ref{sec:numerical}, we illustrate the performance of the proposed algorithm in simulations of a network flow control problem. We conclude and discuss future work in Section \ref{sec:conclusions}.

\paragraph*{Notation}
For a matrix $\mathbf{H}$ with $N$ block-rows and $N$ block-columns, i.e.,
    $\mathbf{H} = 
    \begin{bmatrix}
        H_{11} & H_{12} &\cdots & H_{1N}\\
        \vdots& \ddots\\
        H_{N1} & H_{N2} & \cdots &H_{NN}
    \end{bmatrix}$,
we define
    $[\mathbf{H}]_{ij} := H_{ij}$.
Moreover, we define the following notation for a (dual-indexed) sequence
$(u_{i,t})_{i=1,t=1}^{N,T-1} := (u_{1,1},u_{2,1},\cdots,u_{N,1}, u_{1,T-1},u_{N,T-1},\cdots,,u_{N,T-1}),
$
and $\frown$ to denote concatenation, i.e.,
\begin{align*}
    \begin{split}
    &(u_{i,t})_{i=1,t=1}^{N,\tau-1} \frown (v_{i,t})_{i=1,t=\tau}^{N,T-1}:=(u_{1,1},\cdots,u_{1,\tau-1},v_{1,\tau},\cdots,\\
    &\qquad v_{1,T-1},\cdots, u_{N,1},\cdots,u_{N,\tau-1},v_{N,\tau},\cdots,v_{N,T-1} ).
    \end{split}
\end{align*}
We use $\|\cdot\|$ to denote the 2-norm of a vector or a matrix, depending on its argument. For symmetric matrices $F,G$ with appropriate dimensions, $F \preceq G$ denotes $G-F$ being positive definite. Let $\rho(\cdot)$ be the spectral radius operator. We use $\lambda_{n}(\cdot)$, $\lambda_{min}(\cdot)$ and $\lambda_{max}(\cdot)$ to designate the $n$-th, the minimum and the maximum eigenvalue of a matrix, respectively. Similarly, $\sigma_{n}(\cdot)$, $\sigma_{min}(\cdot)$ and $\sigma_{max}(\cdot)$ denote the $n$-th, the minimum and the maximum singular value. For a positive integer $k$, define $\mathbb{N}_k$ to be the set $\{1,2,\dots,k\}$. Lastly, let $\mathbb{S}_{++}^{n}$ denotes the set of $n$-dimensional square positive definite matrix.

\section{PROBLEM FORMULATION}
\label{sec:problem_formulation}

We consider an $N$-player non-cooperative dynamic game, with discrete-time linear system
\begin{align}
    x_{t+1} &= Ax_{t} + \mathbf{B}\mathbf{u}_{t}, \label{eq:linsys}
\end{align}
where $t \in \mathbb{N}_{T-1}$ with positive integer $T$, $x_{t}\in\mathbb{R}^n$, $x_{1} =\bar{x}_{1}$, $\bar{x}_1 \in \mathbb{R}^{n}$, $A \in \mathbb{R}^{n\times n}$, $\mathbf{B} = [B^{1}, B^{2},\cdots,B^{N}]$, $B^{i} \in \mathbb{R}^{n\times m}\text{ for $i\in \Nplayers$}$, $\mathbf{u}_{t} = [u_{1,t}^{\transpose}, u_{2,t}^{\transpose},\cdots,u_{N,t}^{\transpose}]^{\transpose}$, $u_{i,t}\in \mathbb{R}^{m}\text{ for $i\in \Nplayers$}$, $\transpose$ being the transpose operator, and $m$ and $n$ are positive integers.

Each player chooses $u_{t}^{i},i \in \Nplayers$ to optimise some cost function. The $i$-th player's cost function is
\begin{equation}\label{eq:LQcost}
    J_{i,T}((x_{t})_{t=1}^{T},(u_{i,t})_{i=1,t=1}^{N,T-1}) := \sum_{t=1}^{T-1} g_{i,t}(x_{t}, \mathbf{u}_{t}) + g_{i,T}(x_{T}),
\end{equation}
where $g_{i,t}(x_{t}, \mathbf{u}_{t}) := \frac{1}{N}(x_{t}^{\mathsf{T}}Q_{t}x_{t} + 
    \mathbf{u}_{t}^{\transpose}R_{t}^{i}\mathbf{u}_{t})$,
    $g_{i,T}(x) := \frac{1}{N} x^{\mathsf{T}}Q_{T}x$, and $Q\in\mathbb{S}_{++}^n$.

We consider the following Nash Equilibrium concept.
The sequences $(x_{t}^{*})_{t=1}^{T},(u_{i,t}^{*})_{i=1,t=1}^{N,T-1}$ correspond to a \emph{Feedback Nash Equilibrium}, if and only if the following conditions are satisfied. For $1 \leq \tau \leq T$, $(x_{t}^{*\tau})_{t=1}^{T}$ is generated by the sequence of $(u_{i,t})_{i=1,t=1}^{N,\tau-1} \frown (u_{i,t}^{*})_{i=1,t=\tau}^{N,T-1}$, where $u_{i,t}$ is any given control decision for $i \in \Nplayers$ and $t \in \mathbb{N}_{\tau-1}$. Moreover, $(x_{t}^{(1,\tau)})_{t=1}^{T}$ is generated by $(u_{i,t})_{i=1,t=1}^{N,\tau-1} \frown (u_{1,\tau},u_{2,\tau}^{*},\cdots,u_{N,\tau}^{*}) \frown (u_{i,t}^{*})_{i=1,t=\tau+2}^{N,T-1}$, and similarly to $(x_{t}^{(N,\tau)})_{t=1}^{T}$, which,

\begin{equation}
\label{eq:nashIneq}
    \begin{split}
        \text{Level T}
        &\begin{cases}
            &J_{1,T}((x_{t}^{*T})_{t=1}^{T}, (u_{i,t})_{i=1,t=1}^{N,T-2} \frown (u_{1,T}^{*},u_{2,T}^{*},\dots,u_{N,T}^{*})) \\ & \leq J_{1,T}((x_{t}^{(1,T)})_{t=1}^{T}, (u_{i,t})_{i=1,t=1}^{N,T-2} \frown (u_{1,T},u_{2,T}^{*},\dots,u_{N,T}^{*})),\\ \\
            &J_{2,T}((x_{t}^{*T})_{t=1}^{T}, (u_{i,t})_{i=1,t=1}^{N,T-2} \frown (u_{1,T}^{*},u_{2,T}^{*},\dots,u_{N,T}^{*})) \\ & \leq J_{2,T}((x_{t}^{(2,T)})_{t=1}^{T}, (u_{i,t})_{i=1,t=1}^{N,T-2} \frown (u_{1,T}^{*},u_{2,T},\dots,u_{N,T}^{*})),\\
            & \qquad \qquad \vdots \\
            &J_{N,T}((x_{t}^{*T})_{t=1}^{T}, (u_{i,t})_{i=1,t=1}^{N,T-2} \frown (u_{1,T}^{*},u_{2,T}^{*},\dots,u_{N,T}^{*})) \\ & \leq J_{N,T}((x_{t}^{(N,T)})_{t=1}^{T}, (u_{i,t})_{i=1,t=1}^{N,T-2} \frown (u_{1,T}^{*},u_{2,T}^{*},\dots,u_{N,T})).
        \end{cases}
    \\ &\qquad \qquad \qquad \vdots \\
    \text{Level 1}
        &\begin{cases}
            &J_{1,T}((x_{t}^{*1})_{t=1}^{T}, (u_{1,1}^{*},u_{2,1}^{*},\dots,u_{N,1}^{*}) \frown (u_{i,t}^{*})_{i=1,t=2}^{N,T-1}) \\ & \leq J_{1,T}((x_{t}^{(1,1)})_{t=1}^{T}, (u_{1,1},u_{2,1}^{*},\dots,u_{N,1}^{*}) \frown (u_{i,t}^{*})_{i=1,t=2}^{N,T-1}),\\ \\
            &J_{2,T}((x_{t}^{*1})_{t=1}^{T}, (u_{1,1}^{*},u_{2,1}^{*},\dots,u_{N,1}^{*}) \frown (u_{i,t}^{*})_{i=1,t=2}^{N,T-1}) \\ & \leq J_{2,T}((x_{t}^{(2,1)})_{t=1}^{T}, (u_{1,1}^{*},u_{2,1},\dots,u_{N,1}^{*}) \frown (u_{i,t}^{*})_{i=1,t=2}^{N,T-1}),\\
            & \qquad \qquad \vdots \\
            &J_{N,T}((x_{t}^{*1})_{t=1}^{T}, (u_{1,1}^{*},u_{2,1}^{*},\dots,u_{N,1}^{*}) \frown (u_{i,t}^{*})_{i=1,t=2}^{N,T-1}) \\ & \leq J_{N,T}((x_{t}^{(N,1)})_{t=1}^{T}, (u_{1,1}^{*},u_{2,1}^{*},\dots,u_{N,1}) \frown (u_{i,t}^{*})_{i=1,t=2}^{N,T-1}).
        \end{cases}
    \end{split}
\end{equation}

An ($N$-player) linear quadratic dynamic feedback game (LQDFG) is thus defined as follows.
\begin{definition}[LQDFG]\label{def:LQDFG}
     For $N$ players indexed $i\in\Nplayers$ and a given positive integer $T$, suppose $J_{i,t}(\cdot,\cdot)$ for $t\in\mathbb{N}_{T}$ as defined by \eqref{eq:LQcost}. A linear quadratic dynamic feedback game (LQDFG) problem is concerned with each player $i$ choosing control inputs $u_{i,t}^{*}$ that satisfy \eqref{eq:linsys} and \eqref{eq:nashIneq} with $t \in \mathbb{N}_{T-1}$. 
\end{definition}
We note that there is a close relationship between LQDFGs, and linear-quadratic optimal control problems (LQOCPs), defined below.
\begin{definition}[LQOCP]\label{def:LQOCP}
    For given positive definite $(\bar{Q}_{t})_{t=1}^{T}$ and $(\bar{R}_{t})_{t=1}^{T-1}$ where $T$ is a positive integer, the LQOCP involves finding $\{\mathbf{u}_{t}\}_{t=1}^{T-1}$ such that
    \begin{align}
    \min_{\{\mathbf{u}_{t}\}_{t=1}^{T-1}}\qquad & \sum_{t=1}^{T-1} x_{t}^{\transpose}\bar{Q}_{t}x_{t} + \mathbf{u}_{t}^{\transpose}\bar{R}_{t}\mathbf{u}_{t} + x_{T}^{\transpose}\bar{Q}_{T}x_{T}\label{eq:LQOCP}\\
    \text{s.t.} \qquad &  \eqref{eq:linsys}. \notag
\end{align}
\end{definition}
In particular, we consider the connection between LQDFGs and LQOCPs that give rise to the following recently developed concept of linear-quadratic dynamic feedback potential games (LQDFPGs).
\begin{definition}[LQDFPG \cite{prasad_structure_2023}]\label{def:LQDFPG}
    An LQDFG is referred to as an LQDFPG, if there exists an LQOCP such that the solution of the LQOCP, in feedback form, provides a feedback Nash equilibrium for the LQDFG.
\end{definition}

When the cost-matrices are known \emph{a priori} to the players, the (Nash equilibrium) solution of an LQDFPGs can be found in closed form (cf.\ \cite{prasad_structure_2023} and \cite[Chapter 6]{basar_dynamic_1998}).
However, in practice full information about the cost matrices over the whole time horizon may be unavailable to the players in advance (for example, \cite{westenbroek_feedback_2020}, \cite{kouro_model_2009}).
Hence, in our work, we suppose that at any time $t \in \mathbb{N}_{T-1 - W}$ where $W\in\mathbb{N}_{T-2} \cup \{0\}$ is a given preview window length, only the initial condition of the system \eqref{eq:linsys} and the (partial) sequences of cost matrices $(Q_{\tau})_{\tau=1}^{t+W}$ and $(R_{\tau}^i)_{i=1,\tau=1}^{N,t+W}$ are known to all players.
Let the cost-function information available to all players at time $t$ be
\begin{equation}\label{eq:history}
    \mathcal{H}_{t} := (\bar{x}_{1}, (Q_{\tau})_{\tau=1}^{t+W}, (R_{\tau}^i)_{i=1,\tau=1}^{N,t+W}).
\end{equation}
The focus of our work is to propose a novel control policy for each player in an LQDFPG that uses the information available to them only at time $t$, and to investigate the resulting deviation in performance from a Nash equilibrium by using the concept of \emph{dynamic social regret}.
We specifically consider player-feedback control policies $\pi^i (\cdot, \cdot)$ of the form
\begin{align*}
    u_t^i = \pi^i(x_t, \mathcal{H}_t),
\end{align*}
where $i \in \Nplayers$ and adopt the following notion of \emph{dynamic social regret}.

\begin{definition}[Dynamic Social Regret]
For any input $(\mathbf{u}_{t})_{t=1}^{T-1}$ and the associated state sequence $(x_{t})_{t=1}^{T}$, we define the \emph{dynamic social regret} as
\begin{equation}
    \label{eq:regret}
    \begin{split}
        &\text{Regret}_{T}((\mathbf{u}_{t})_{t=1}^{T-1}) := \\
        &\sum_{i=1}^{N} J_{i,T}((x_{t})_{t=1}^{T},(\mathbf{u}_{t})_{t=1}^{T-1}) - J_{i,T}((x_{t}^{*})_{t=1}^{T},(\mathbf{u}_{t}^{*})_{t=1}^{T-1}),
    \end{split}
\end{equation}
\end{definition}
where $((x_{t}^{*})_{t=1}^{T},(\mathbf{u}_{t}^{*})_{t=1}^{T-1})$ is the sequence satisfy \eqref{eq:nashIneq}.
Our consideration of \emph{dynamic social regret} is motivated by the concept of dynamic regret from \cite[Equation (5)]{chen_regret_2023} that captures the discrepancy between the performance of a proposed algorithm and the best policies chosen in hindsight.

We develop our algorithm and analysis under the following assumptions on the systems structure and the cost matrices. For $i\in \Nplayers$ and $t \in \mathbb{N}_{T-1}$, let $R_{t}^{i}$ admits the following block structure:
    \begin{align}
   &R_{t}^{i} := 
   \begin{bmatrix}
       [R_{t}^{i}]_{11} & [R_{t}^{i}]_{12} & \cdots & [R_{t}^{i}]_{1N}\\
       \vdots & \ddots\\
       [R_{t}^{i}]_{N1} & [R_{t}^{i}]_{N2} & \cdots & [R_{t}^{i}]_{NN}
   \end{bmatrix}\in \mathbb{R}^{Nn\times Nn}\text{ with }R_{ij}\in \mathbb{R}^{n\times n}.
   \end{align}
The matrices $Q_{t}$, $[R_{t}^{i}]_{jk}$, $A$ and $B^{i}$ where $i,j,k \in \Nplayers$ satisfy the following assumptions.
\begin{assumption}\label{assumption:bounds}
    Matrices $Q_{t},R_{t}^{i} \in \mathbb{S}_{++}^{n}$, and $[R_{t}^{i}]_{ij} = ([R_{t}^{j}]_{ji})^{\transpose}$.
    Moreover, there exist $Q_{min}, Q_{max}\in \mathbb{S}_{++}^{n}$ and $R_{min}, R_{max}\in \mathbb{S}_{++}^{m}$, such that
    for $ t \in \mathbb{N}_{T-1}$,
    \begin{align*}
        Q_{min} &\preceq Q_{t} \preceq Q_{max}, \quad Q_{t} \in \mathbb{S}^{n}_{++},
    \end{align*}
    \begin{equation}\label{eq:positiveR}
        R_{min} \preceq 
        \begin{bmatrix}
            [R_{t}^{1}]_{11} & \cdots & [R_{t}^{1}]_{1N}\\
            \vdots & \ddots \\
            [R_{t}^{N}]_{N1} & \cdots & [R_{t}^{N}]_{NN}
        \end{bmatrix}
        \preceq R_{max}.
    \end{equation}
\end{assumption}
The above assumption ensures that the eigenvalues for all cost matrices are positive and finite. This guarantees that all cost matrices in the LQOCP associated with the LQDFG are bounded, which coincides with standard assumption in LQR control literature, e.g., \cite[Assumption 1]{chen_regret_2023}, \cite[Assumption 1]{sun_receding-horizon_2023}. See Corollary \ref{corollary:boundedR}, and \ref{corrolary:boundedK} in the Appendix. 
\begin{assumption}\label{assumption:controllable}
    Matrix $A$ has full rank, and there exist $\bar{K}$, such that $\rho(A + \contB \bar{K}) < 1$.
\end{assumption}
The above assumption is to make sure that there exists a stabilizing controller $\bar{K}$ for the system $(A,\mathbf{B})$.
\begin{assumption}\label{assumption:lowerQ}
    For any given $t \in \mathbb{N}_{T-1}, i,j\in \Nplayers$, define
    \begin{align*}
        [\mathbf{R_{t}}]_{ij} = 
        \begin{cases}
            0 & \text{if $i = 1$,}\\
            [R_{t}^{i}]_{ij}-[R_{t}^{1}]_{ij} & \text{otherwise}.
        \end{cases}
    \end{align*}
    Matrices $Q_{t}, \mathbf{R_{t}}$ satisfy
        $\lambda_{\min}(Q_{t}) > \max(0,\sigma_{max}(\contB)\lambda_{max}(\mathbf{R_{t}}))$.
\end{assumption}
The above assumption ensures that the cost matrices in the LQOCP associated with the LQDFG are positive definite, see Corollary \ref{corollary:positiveQ} from the Appendix. {\color{red} When eigenvalues of $Q_{t}$ are sufficiently large, players will prioritise efforts to push the state towards the origin together rather than saving control efforts.}

In the next section, we present our algorithm for finding controls and provide the \emph{regret} upperbound under such an algorithm.

\section{Proposed Approach and Regret Analysis}\label{sec:approach}
In this section, we propose an algorithm and analyse its regret for our online LQDFPG problem.

\subsection{Algorithm}

Our algorithm involves two steps at each time step $t$ (for each player) --- a prediction step and an associated tracking step.

\paragraph{Prediction} 

We first predict a trajectory by using the current cost matrices and setting the future unknown cost matrices to be equal to the known value at time $t+W$. That is, define 
\begin{equation*}
\begin{split}
    \bar{\mathcal{H}}_{t} := (&\bar{x}_{1}, (Q_{\tau})_{\tau=1}^{t+W} \frown(Q_{t+W})_{\tau=t+W+1}^{T},\\
    &(R_{\tau}^{i})_{i=1,\tau=1}^{2,t+W} \frown(R_{t+W}^{i})_{i=1,\tau=t+W+1}^{N,T-1}),
\end{split}
\end{equation*}
and our predicted Nash Equilibrium trajectories given the information available at $t$ are

\begin{equation*}
    ((x_{\tau|t})_{\tau=1}^{T},(\mathbf{u}_{\tau|t})_{\tau=1}^{T-1}) = \text{DFLGame}(\bar{\mathcal{H}}_{t},T)
\end{equation*}
where we define $\text{DFLGame}(\cdot, \cdot)$ as an operator that uses $\mathcal{H}_{T}$ to generate a Feedback Nash Equilibrium, for the $N$-player LQ dynamic game with dynamics \eqref{eq:linsys}, horizon $T$, and the cost functions \eqref{eq:LQcost} with the cost matrices in $\bar{\mathcal{H}}_{t}$.

\paragraph{Prediction Tracking} We propose the following feedback control policy to track the predicted Nash Equilibrium trajectories
\begin{equation}\label{eq:policy}
    \pi(x_{t}, \bar{\mathcal{H}}_{t}) := \bar{K}(x_{t}-x_{t|t}) + \mathbf{u}_{t|t},
\end{equation}
where $\bar{K}\in \mathbb{R}^{m\times n}$ is a gain matrix such that $\rho(A+\mathbf{B}\bar{K}) < 1$. Policy \eqref{eq:policy} can be written in the player specific form
\begin{align*}
\begin{bmatrix}
    \pi^{1}(x_{t}, \bar{\mathcal{H}}_{t})\\
    \pi^{2}(x_{t}, \bar{\mathcal{H}_{t}})\\
    \vdots\\
    \pi^{N}(x_{t}, \bar{\mathcal{H}_{t}})
\end{bmatrix}=
    \begin{bmatrix}
        [\bar{K}]_{1}\\
        [\bar{K}]_{2}\\
        \vdots\\
        [\bar{K}]_{N}
    \end{bmatrix}(x_{t}-x_{t|t}) + 
    \begin{bmatrix}
        [\mathbf{u}_{t|t}]_{1}\\
        [\mathbf{u}_{t|t}]_{2}\\
        \vdots\\
        [\mathbf{u}_{t|t}]_{N}
    \end{bmatrix},
\end{align*}
where $\pi^{i}(x_{t}, \bar{\mathcal{H}_{t}})$ is the policy for the $i$-th player, $i \in \Nplayers$, at time $t$, $[\bar{K}]_{i}$ and $[\mathbf{u}_{t|t}]_{i}$ have appropriate dimensions.
In the next section, we show the regret upperbound for this algorithm.


\subsection{Regret Analysis}
The following theorem illustrates the regret upperbound for the proposed algorithm from the previous section.

\begin{theorem}[\emph{Regret} Bound]\label{thm:main}
    Consider the linear system \eqref{eq:linsys}, a given time horizon $T \geq 1$, and a preview window length $W\in \mathbb{N}_{T-1} \cup \{0\}$. Suppose that at time $t \in \mathbb{N}_{T-1}$ the control input $u_t$ is generated by policy $\pi(\cdot,\cdot)$ as given by \eqref{eq:policy}. Under Assumptions \ref{assumption:bounds}-\ref{assumption:potentialRepeat}, the regret defined by \eqref{eq:regret} satisfies
    \begin{equation}\label{eq:mainBound}
        \text{Regret}_{T}((\mathbf{u}_{t})_{t=1}^{T-1})< C_{1}\gamma^{W} + C_{2}\varepsilon_{K},
    \end{equation}
    where $\gamma \in (0,1)$ and $\varepsilon_{K}$ is monotonically increasing w.r.t. $\gamma$, $\|\contB\|$, and $(\lambda_{min}(\bar{Q}_{min}))^{-1}$. Moreover, constants $C_{1}$ and $C_{2}$ are monotonically increasing w.r.t. $\lambda_{max}(R_{max})$ $\lambda_{max}(Q_{max})$,  $(\rho(A+\contB\bar{K}))^{-1}$ and $(\lambda_{max}(\bar{P}_{max})-\lambda_{min}(\bar{Q}_{min}))^{-1}$. 
    
\end{theorem}

\begin{remark}
    For the case where $N=1$, we have $\varepsilon_{K}=0$. The \emph{dynamic social regret} upperbound in \eqref{eq:mainBound} decays exponentially in $W$. This coincides with the behaviour of the upperbound for \emph{dynamic regret} for optimal control problem defined in \cite[Equation (5)]{chen_regret_2023} for \cite[Problem 1a]{chen_regret_2023}. 
\end{remark}
\begin{remark}
    For a fixed $\mathcal{H}_{T}$ of an LQDFPG, if preview horizon $W$ increases, the term $C_{1}\gamma^{W}$ decays exponentially fast. When $W$ is large enough, the \emph{regret} upperbound is dominaned by $\varepsilon_{K}$.
\end{remark}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{NUMERICAL SIMULATIONS}\label{sec:numerical}
In this section, we numerically illustrate the performance of our proposed algorithm. We consider a network-flow control problem similar to the one studied in \cite[Section VI]{zazo_dynamic_2016} in which two users transmit messages through a shared relay.
The users aim to minimise transmission costs and maintain the relay's battery at a nominal value. 
The battery level evolves as a function of the users' transmissions and the environment according to the equation 
\begin{equation}\label{eq:expEquations}
    x_{t+1} = 
    \begin{bmatrix}
        a & 0\\
        0 & 0.9
    \end{bmatrix}
    x_{t} + 
    \begin{bmatrix}
        -b_{1} & -b_{2}\\
        0 & 0
    \end{bmatrix}\mathbf{u}_{t},
\end{equation}
where $a \geq 1$ is the charge rate of the battery, $x_{t}$ is the deviation between the relay's battery level from its nominal value, and $u_{t}^{i}$ is the message transmission rate from the $i$-th user, $i=\Nplayers$.
The cost matrices $Q_{t}$ penalise deviation of the relay's battery level from its nominal value, and $R_{t}^{i}$ penalise the data transmission. 
Users have limited knowledge of these future cost matrices over a preview window of length $W \in \mathbb{N}_{T-1}\cup \{0\}$ due to the unpredictable environmental conditions affecting battery recharge performance, and the price of transmission being set externally.


Before specific values of $a,b_{1}$ and $b_{2}$ are introduced,
the cost matrices are
\begin{equation}\label{eq:costSettings}
    Q_{t} = 
    \begin{bmatrix}
        l_{t} & -d_{t}\\
        -d_{t} & 0
    \end{bmatrix},\
    R_{t}^{1} = 
    \begin{bmatrix}
        r_{1,t} & 0\\
        0 & 0
    \end{bmatrix},\
    R_{t}^{2} = 
    \begin{bmatrix}
        0 & 0\\
        0 & r_{2,t}
    \end{bmatrix},
\end{equation}
where $\frac{b_{1}^{2}}{r_{1,t}}=\frac{b_{2}^{2}}{r_{2,t}} = \beta_{t}$. 
The Proposition below claim that such systems and costs lead to a LQ potential dynamic game.

\begin{proposition}
    Suppose $A$ is a full rank square matrix, and matrices $\contB$,$R_{t}^{i},Q_{t}$ are defined as per \eqref{eq:expEquations} and \eqref{eq:costSettings}.
    For $0 \leq t \leq T-1, i\in \{1,2\}$, if $\frac{b_{1}^{2}}{r_{1,t}} = \frac{b_{2}^{2}}{r_{2,t}}$, then parameters $P_{t},\Theta_{t}$ satisfy conditions \eqref{eq:costFPDG4}-\eqref{eq:costFPDG3}.
    
\end{proposition}
\begin{proof}
    For $t = T$, since $P_{T}^{1} = P_{T}^{2} = Q_{T}$, and
    \begin{align*}
        \Theta_{T-1} = 
        \begin{bmatrix}
            r_{1,T-1} & 0\\
            0 & r_{2,T-1}
        \end{bmatrix}
        + \contB^{\transpose}Q_{T}\contB,
    \end{align*}
    we have 
    $\Theta_{T-1} \succ 0 $, then we reach the conclusion.
    For $t = T-1$, 
    \begin{align*}
        P_{T-1}^{1}-P_{T-1}^{2} = K_{T-1}^{\transpose}(R_{T-1}^{1}-R_{T-1}^{2})K_{T-1}.
    \end{align*}
    We next claim that $\contB\Theta_{T-1}^{-1}(R_{T-1}^{1}-R_{T-1}^{2})\Theta_{T-1}^{-1}\contB^{\transpose}$.
    Since
    \begin{align*}
        &\contB\Theta_{T-1}^{-1}(R_{T-1}^{1}-R_{T-1}^{2})\Theta_{T-1}^{-1}\contB^{\transpose} = \\
        &\frac{1}{\det(\Theta)^{2}}
        \begin{bmatrix}
            -b_{1} & -b_{2}\\
            0 & 0
        \end{bmatrix}
        \begin{bmatrix}
            r_{2,T-1}+B^{2\transpose}P_{T-1}^{2}B^{2\transpose} & B^{2\transpose}P_{T-1}^{2}B^{1\transpose}\\
            B^{1\transpose}P_{T-1}^{1}B^{2\transpose} & r_{1,T-1}+B^{1\transpose}P_{T-1}^{1}B^{1\transpose}
        \end{bmatrix}\\
        &\qquad 
        \begin{bmatrix}
            r_{1,T-1} & 0\\
            0 & -r_{2,T-1}
        \end{bmatrix}
        \begin{bmatrix}
            r_{2,T-1}+B^{2\transpose}P_{T-1}^{2}B^{2\transpose} & B^{2\transpose}P_{T-1}^{2}B^{1\transpose}\\
            B^{1\transpose}P_{T-1}^{1}B^{2\transpose} & r_{1,T-1}+B^{1\transpose}P_{T-1}^{1}B^{1\transpose}
        \end{bmatrix}\\
        &\qquad \begin{bmatrix}
            -b_{1} & 0\\
            -b_{2} & 0
        \end{bmatrix}
    \end{align*}
    Due to
    \begin{align*}
        \begin{bmatrix}
            \alpha & \beta\\
            \beta & \gamma
        \end{bmatrix}
        \begin{bmatrix}
            h_{1} & 0\\
            0 & h_{2}
        \end{bmatrix}
        \begin{bmatrix}
            \alpha & \beta\\
            \beta & \gamma
        \end{bmatrix} = 
        \begin{bmatrix}
            h_{1}\alpha^{2}+h_{2}\beta^{2} & h_{1}\alpha\beta + h_{2}\beta\gamma\\
            h_{1}\alpha\beta + h_{2}\beta\gamma & h_{1}\beta^{2} + h_{2}\gamma
        \end{bmatrix},
    \end{align*}
    and
    \begin{align*}
        B^{2\transpose}P_{T-1}B^{2} = b_{2}^{2}[Q_{T}]_{11},\\
        B^{1\transpose}P_{T-1}B^{1} = b_{1}^{2}[Q_{T}]_{11},
    \end{align*}
    substitute $h_{1} = r_{1,T-1}, h_{2}=-r_{2,T-1},\cdots$, we have
    \begin{align*}
        \frac{h_{1}\alpha}{-h_{2}\gamma} = \frac{r_{1,T-1}}{r_{2,T-1}}\frac{r_{2,T-1}+b_{2}^{2}[Q_{T}]_{11}}{r_{1,T-1}+b_{1}^{2}[Q_{T}]_{11}} = \frac{r_{1,T-1}}{r_{2,T-1}}\frac{r_{2,T-1}}{r_{1,T-1}} = 1,
    \end{align*}
    therefore, $h_{1}\alpha\beta + h_{2}\beta\gamma=0$.
    Moreover,
    \begin{align*}
        &
        \begin{bmatrix}
            -b_{1} & -b_{2}\\
            0 & 0
        \end{bmatrix}
        \begin{bmatrix}
            c_{1} & 0\\
            0 & c_{2}
        \end{bmatrix}
        \begin{bmatrix}
            -b_{1} & 0\\
            -b_{2} & 0
        \end{bmatrix}
        =
        \begin{bmatrix}
            c_{1}b_{1}^{2}+c_{2}b_{2}^{2} & 0\\
            0 & 0
        \end{bmatrix}.
    \end{align*}
    Here, $c_{1} = r_{1,T-1}(r_{2,T-1}+b_{2}^{2}[Q_{T}]_{11}), c_{2} = -r_{2,T-1}(r_{1,T-1}+b_{1}^{2}[Q_{T}]_{11})$. Apply $\frac{b_{1}^{2}}{b_{2}^{2}} = \frac{r_{1,T-1}}{r_{2,T-1}}$ again, we have $c_{1}b_{1}^{2}+c_{2}b_{2}^{2}=0$. Therefore, $K_{T-1}^{\transpose}(R_{T-1}^{1}-R_{T-1}^{2})K_{T-1} = 0$.
    
    Let's assume that $P_{t+1}^{1}-P_{t+1}^{2}=0$. Due to 
    \begin{align*}
        \Theta_{t} = 
        \begin{bmatrix}
            r_{1,t} & 0\\
            0 & r_{2,t}
        \end{bmatrix}
        + \contB^{\transpose}P^{1}_{t+1}\contB,
    \end{align*}
    we have $\Theta_{t} \succ 0$, therefore $\det(\Theta_{t})$ is non-zero.
    Consider 
    \begin{align*}
        K_{t}^{\transpose}(R_{t}^{1}-R_{t}^{2})K_{t}=
        \contB\Theta_{t}^{-1}(R_{t}^{1}-R_{t}^{2})\Theta_{t}^{-1}\contB^{\transpose}.
    \end{align*}
    By repeating the steps above and use the relation of $B^{1\transpose}P_{t+1}^{1}B^{1}=b_{1}^{2}[P_{t+1}^{1}]_{11}$, we have
    \begin{align*}
        \frac{h_{1}\alpha}{-h_{2}\gamma} = \frac{r_{1,t}}{r_{2,t}}\frac{r_{2,t}+b_{2}^{2}[P_{t+1}^{2}]_{11}}{r_{1,t}+b_{1}^{2}[P_{t+1}^{1}]_{11}} = 1,
    \end{align*}
    and 
    \begin{align*}
        \frac{b_{1}^{2}}{b_{2}^{2}} = \frac{r_{1,t}}{r_{2,t}},
    \end{align*}
    we can arrived with the conclusion for all $0 \leq t \leq T-1$.
\end{proof}
\begin{remark}
    If we set $\frac{b_{i}^{2}}{r_{i,t}}=\frac{b_{j}^{2}}{r_{j,t}}$ for $i \in \Nplayers, t\in \mathbb{N}_{T}$, we still yields a potential game and the proof is similar to the two-player case. In this case, 
    \begin{align*}
    R_{t}^{1}-R_{t}^{i}=
        \begin{bmatrix}
            r_{1,t} & 0 & \cdots & \cdots & 0\\
            \vdots & \ddots \\
            0 & \cdots & -r_{i,t} & \cdots & 0\\
            0 & \cdots & 0 & \cdots & 0
        \end{bmatrix}.
    \end{align*}
    Moreover, these parameters satisfy Assumption \ref{assumption:potentialRepeat}.
\end{remark}


The above parameters and assumption lead to an LQ potential dynamic game. In the simulations, we consider $a=1.6,b_{1}=0.85,b_{2} =0.89$.
The preview window $W$ varies from $0$ to $6$ and the time horizon $T$ ranges from $1$ to $200$. We consider cost matrices drawn randomly according to $\beta_{t} \sim \mathcal{U}[10,110]$, $l_{t} \sim \mathcal{U}[10,110]$ and $d_{t}\sim \mathcal{U}[-110,-10]$, where $\mathcal{U}[\cdot,\cdot]$ denotes the uniform distribution. 


The plots in Figure \ref{fig:0preview},  \ref{fig:1preview}, \ref{fig:0preview2} and \ref{fig:1preview2} show the average regret computed from $1000$ Monte Carlo trials, with a preview window length of {\color{red}$0$ and $1$}, respectively. The average regret appears to remain almost constant from $T = 20$ for a preview window length of $0$, and $T = 10$ for a preview window length of $1$. These plots empirically illustrate the main result. The plots in Figure \ref{fig:8timehorizon}, \ref{fig:69timehorizon}, \ref{fig:8timehorizon2} and \ref{fig:69timehorizon2} illustrate how the (log) average regret varies with preview window length for fixed $T=8$ and $T=70$, respectively. The trends depicted in Figure \ref{fig:8timehorizon}, \ref{fig:69timehorizon}, \ref{fig:8timehorizon2} and \ref{fig:69timehorizon2} show an exponential decay as the preview window length grows from $0$ to $6$, which illustrates the theoretical upperbound in Theorem \ref{thm:main}. Moreover, in 2-player case, the regret saturates at about $T=15$ as illustrated in Figure \ref{fig:0preview} and  \ref{fig:1preview}. In 6-player case, the regret saturates at about $T=20$ as illustrated in Figure \ref{fig:0preview} and  \ref{fig:1preview}, which suggests the regret takes longer time to saturate as the number of players grows.

\begin{figure}
        \label{fig:experiments}
     \centering
     \subfigure[]{
         \includegraphics[width=.22\textwidth]{regAvgMeFixGamePlayers2Preview6Time40Monte1000Window1.pdf}
    \label{fig:0preview}}
     \subfigure[]{
         \includegraphics[width=.22\textwidth]{regAvgMeFixGamePlayers2Preview6Time40Monte1000Window3.pdf}
    \label{fig:1preview}}
    \\
     \subfigure[]{
         \includegraphics[width=.22\textwidth]{regAvgMeFixGamePlayers2Preview6Time40Monte1000Time7.pdf}
    \label{fig:8timehorizon}}
     \subfigure[]{
         \includegraphics[width=.22\textwidth]{regAvgMeFixGamePlayers2Preview6Time40Monte1000Time20.pdf}
    \label{fig:69timehorizon}}
    \caption{Performance measure $\text{Regret}_{T}$ in case $N=2$. (a) Regret vs. Time Horizon with $W=0$;  (b) Regret vs. Time Horizon with $W=1$; (c) Regret vs. Preview Window Length in $T=20$; (d) Regret vs. Preview Window Length in $T = 35$.}
\end{figure}

\begin{figure}
        \label{fig:experiments2}
     \centering
     \subfigure[]{
         \includegraphics[width=.22\textwidth]{regAvgMeFixGamePreview6Time50Monte1000Window1.pdf}
    \label{fig:0preview2}}
     \subfigure[]{
         \includegraphics[width=.22\textwidth]{regAvgMeFixGamePreview6Time50Monte1000Window3.pdf}
    \label{fig:1preview2}}
    \\
     \subfigure[]{
         \includegraphics[width=.22\textwidth]{regAvgMeFixGamePreview6Time50Monte1000Time7.pdf}
    \label{fig:8timehorizon2}}
     \subfigure[]{
         \includegraphics[width=.22\textwidth]{regAvgMeFixGamePreview6Time50Monte1000Time25.pdf}
    \label{fig:69timehorizon2}}
    \caption{Performance measure $\text{Regret}_{T}$ in case $N=6$ for simulated systems. (a) Regret vs. Time Horizon with $W=0$; (b) Regret vs. Time Horizon with $W=1$; (c) Regret vs. Preview Window Length in $T=7$; (d) Regret vs. Preview Window Length in $T = 25$.}
\end{figure}

\section{CONCLUSION AND FUTURE WORK}\label{sec:conclusions}
This paper introduces the online feedback potential dynamic game problem and proposes a novel algorithm for solving this problem. Furthermore, the notion of  dynamic social regret in order to quantify the performance of the algorithm is proposed and the performance of the proposed algorithm under this notion of regret is evaluated. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \section{ACKNOWLEDGMENTS}

% The authors gratefully acknowledge the contribution of National Research Organization and reviewers' comments.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bibliographystyle{plain}
\bibliography{References}
\appendix
Before stating the proof of Theorem~\ref{thm:main}, in the next subsection, we introduce several necessary lemmas and propositions. 
\subsection{Auxiliary Lemmas}
\begin{lemma}
    For $t\in \mathbb{N}_{T-1},i,j\in \{1,2,\cdots,N\}$,
    define
        \begin{equation}\label{eq:Theta}
        [\Theta_{t}]_{ij} := [R_{t}]^{i}_{ij} + B^{i\transpose}P_{t+1}^{i}B^{j},
        \end{equation}
    where $\{R_{t}^{i}\}_{i=1}^{N},Q_{t}$ satisfy Assumption \ref{assumption:bounds}. and
    \begin{equation}\label{eq:costFPDG4}
        P_{T}^{i} =Q_{T},
    \end{equation}
        \begin{equation}\label{eq:costFPDG1}
            [R_{t}^{i}]_{ij} + B^{i\transpose}P_{t+1}^{i}B^{j} = ([R_{t}^{j}]_{ji} + B^{j\transpose}P_{t+1}^{j}B^{i})^{\transpose},
        \end{equation}
        \begin{equation}\label{eq:costFPDG2}
            \Theta_{t} \in \mathbb{S}_{++}^{Nm},
        \end{equation}
        \begin{equation}\label{eq:costFPDG3}
        \mathbf{B}^{\transpose}P_{t}^{i}A=\mathbf{B}^{\transpose}P_{t}^{j}A.
        \end{equation}
    Then, the LQDFG in the sense of Definition \ref{def:LQDFG} parameters is an LQDFPG in the sense of Definition \ref{def:LQDFPG}.
\end{lemma}
\begin{proof}
    At time instant $T$, set $\bar{Q}_{T} = Q_{T}^{1}$. By \eqref{eq:costFPDG4}, we have $\bar{P}_{T} = P_{T}^{1}$, then we have $\contB^{\transpose}\bar{P}_{T}A = \contB^{\transpose}\bar{P}_{T}^{i}A$ for $i = \{1,\cdots,N\}$ by \eqref{eq:costFPDG3}.
    Let 
    \begin{align*}
        &\Rgame_{t} = \Theta_{t} - \contB^{\transpose}\Pgame_{t+1}\contB,\\
        &\Qgame_{t} = Q_{t}^{1} + K_{t}^{\transpose}(R_{t}^{1} - \Rgame)K_{t},
    \end{align*}
    we claim that $K_{t} = \Kgame_{t}$ and $\Pgame_{t} = P_{t}^{1}$, and as consequence $\contB^{\transpose}\Pgame_{t}A = \contB^{\transpose} P_{t}^{i}A$ for $i \in \Nplayers, t\in \mathbb{N}_{T-1}$. 
    We now verify the case of $t = T-1$. Since $\Rgame_{T-1} = \Theta_{T-1} - \contB^{\transpose}\Pgame_{T}\contB$, this implies
    \begin{align*}
        K_{T-1} &= -\Theta_{T-1}^{-1}
        \begin{bmatrix}
            B^{1\transpose}P_{T}^{1}\\
            \vdots\\
            B^{N\transpose}P_{T}^{N}
        \end{bmatrix}A\\
        &= -\Theta_{T-1}^{-1}\contB^{\transpose}P_{T}^{1}A\text{(by \eqref{eq:costFPDG3})}\\
        &= -(\RBPGame{T})^{-1}\contB^{\transpose}\Pgame_{T}A\text{(by \eqref{eq:costFPDG1})}\\
        &= \Kgame_{T-1}.
    \end{align*}
    Then, using the above, we have that
    \begin{align*}
        \Pgame_{T-1} - P_{T-1}^{1} &= \Qgame_{T-1}-Q_{T-1}^{1} + K_{T-1}^{\transpose}(\Rgame_{T-1}-R_{T-1}^{1})K_{T-1} \\
        &+ (A+\contB K_{T-1})^{\transpose}(\Pgame_{T}-P_{T}^{1})(A+\contB K_{T-1})\\
        &= 0.
    \end{align*}
    Follow by similar procedure as above, we can verify that 
    $K_{t} = \Kgame_{t}$ for $t = \Timelen$. The above proof is similar to the proof of \cite[Theorem 6]{prasad_structure_2023}.
\end{proof}
The above lemma is N-player case of \cite[Theorem 6]{prasad_structure_2023} when $Q_{t}^{i}=Q_{t}^{j}$ for $t\in \mathbb{N}_T, i,j \in \{1,\cdots,N\}$.

\begin{lemma}\label{lemma:gamePGrelation}
    Consider an LQDFPG and an LQOCP described by Definitions \ref{def:LQDFG} and \ref{def:LQOCP}, respectively. Under Assumption \ref{assumption:bounds}, the Feedback Nash Equlibrium for the LQDFPG defined in Definition \ref{def:LQDFG} by parameters $\{\bar{x}_{1},\{Q_{t}\}_{t=1}^{T},\{R_{t}^{i}\}_{i=1,t=1}^{N,T-1}\}$, is identical to the solutions of LQOCP defined in Definition \ref{def:LQOCP}, by parameters $\{\bar{x}_{1},\{\bar{Q}_{t}\}_{t=1}^{T},\{\bar{R}_{t}\}_{t=1}^{T-1}\}$, if
    \begin{align*}
        &\bar{P}_{T} = \bar{Q}_{T},\\
        &\bar{\Theta}_{t} = \bar{R}_{t} + \contB^{\transpose}\bar{P}_{t+1}\contB,\\
        &\bar{K}_{t} = \bar{\Theta}_{t}^{-1}\contB^{\transpose}\bar{P}_{t+1}A,\\
        &\bar{P}_{t} = \bar{Q}_{t} + \bar{K}_{t}^{\transpose}\bar{R}_{t}\bar{K}_{t} + (A+\contB\bar{K}_{t})^{\transpose}\bar{P}_{t+1}(A+\contB\bar{K}_{t}),\\
        &\bar{\Theta}_{t} \in \mathbb{S}_{++}^{Nm},\\
        &[R_{t}^{i}]_{ii} + B^{i\transpose}P_{t+1}^{i}B^{i} = [\bar{R}_{t}]_{ii} + B^{i\transpose}\bar{P}_{t+1}B^{i},\\
        &B^{i\transpose}P_{t+1}^{i}A = B^{i\transpose}\bar{P}_{t+1}A,\\
        &[R_{t}^{i}]_{ij} + B^{i\transpose}P_{t+1}^{i}B^{j} = [\bar{R}_{t}]_{ij} + B^{i\transpose}\bar{P}_{t+1}B^{j},i\neq j,\\
        &[R_{t}^{i}]_{ij} + B^{i\transpose}P_{t+1}^{i}B^{j} = ([R^{j}_{t}]_{ji} + B^{j\transpose}P^{j}_{t+1}B^{i})^{\transpose},
    \end{align*}
    for $i,j\in \Nplayers$ and $t \in \mathbb{N}_{T-1}$. 
\end{lemma}
\begin{proof}
    The proof of the above lemma is similar to the proof of \cite[Theorem 5]{prasad_structure_2023} by \cite[Equation (21c)]{prasad_structure_2023} to $x_{t}^{\transpose}Q_{t}x_{t} + \sum_{n=1}^{N}\sum_{m=1}^{N} u_{n,t}^{\transpose}[R_{t}^{i}]_{nm}u_{m,t}$ and apply \cite[Theorem 3]{prasad_structure_2023} to yield the conclusion from the above lemma.
\end{proof}

\begin{lemma}
    For a given positive integer $T$, define
        $\Omega := ((\bar{Q}_{1},\bar{Q}_{2},\cdots,\bar{Q}_{T},\bar{R}_{1},\cdots,\bar{R}_{T-1})|\mathcal{K})$,
    where $\mathcal{K}$ is the set of conditions that, at time instant $T$, $\bar{Q}_{T}$ is such that
            $\mathbf{B}^{\transpose}\bar{Q}_{T}A = \mathbf{B}^{\transpose}Q_{T}A$.
        Let $\bar{P}_{T}$ satisfy
            $\mathbf{B}^{\transpose}\bar{P}_{T}A = \mathbf{B}^{\transpose}Q_{T}A$, and define $\bar{R}_{t}$ as
            \begin{equation}\label{eq:matrixR}
            \bar{R}_{t} := \Theta_{t} - \mathbf{B}^{\transpose}\bar{P}_{t+1}\mathbf{B},
            \end{equation}
        where $\Theta_{t} \in \mathbb{S}_{++}^{Nm}$,
        with $\bar{Q}_{t}$ such that
            $\bar{Q}_{t} = Q_{t} + K_{t}^{\transpose}(R_{t}^{1}-\bar{R}_{t})K_{t}$,
        where
        \begin{equation*}
            K_{t} = \Theta_{t}^{-1}
            \begin{bmatrix}
                B^{1\transpose}P_{t+1}^{1}\\
                \vdots\\
                B^{N\transpose}P_{t+1}^{N}
            \end{bmatrix}
            A,\quad t\in \mathbb{N}_{T-1}.
        \end{equation*}
    Every element in $\Omega$ leads to an LQOCP which is equivalent to an LQDFPG. Further, $\Omega$ is non-empty.
\end{lemma}
\begin{proof}
    The proof of the above Lemma is similar to the proof of \cite[Theorem 7]{prasad_structure_2023}.
\end{proof}

\begin{corollary}\label{corollary:boundedR}
    Under Assumptions \ref{assumption:bounds} and \ref{assumption:controllable}, $\bar{R}_{t}$ defined in \eqref{eq:matrixR} satisfies $0 \prec R_{min} \preceq \bar{R}_{t} \preceq R_{max}$,
    for $t \in \mathbb{N}_{T-1}$.
\end{corollary}
\begin{proof}
    By definition of $\bar{R}_{t}$, we have
    \begin{align*}
        \bar{R}_{t} &= 
        \begin{bmatrix}
            [R_{t}^{1}]_{11} & \cdots & [R_{t}^{1}]_{1N}\\
            \vdots & \ddots\\
            [R_{t}^{N}]_{N1} & \cdots & [R_{t}^{N}]_{NN}
        \end{bmatrix}
        + 
        \begin{bmatrix}
            B^{1\transpose}P_{t+1}^{1}\\
            \vdots\\
            B^{N\transpose}P_{t+1}^{N}
        \end{bmatrix}\mathbf{B}
        - \mathbf{B}^{\transpose}\bar{P}_{t+1}\mathbf{B}\\
        &= \begin{bmatrix}
            [R_{t}^{1}]_{11} & \cdots & [R_{t}^{1}]_{1N}\\
            \vdots & \ddots\\
            [R_{t}^{N}]_{N1} & \cdots & [R_{t}^{N}]_{NN}
        \end{bmatrix}
        + 
        (\begin{bmatrix}
            B^{1\transpose}P_{t+1}^{1}\\
            \vdots\\
            B^{N\transpose}P_{t+1}^{N}
        \end{bmatrix}-
        \begin{bmatrix}
            B^{1\transpose}\bar{P}_{t+1}\\
            \vdots\\
            B^{N\transpose}\bar{P}_{t+1}
        \end{bmatrix}
        )\mathbf{B}
    \end{align*}
    Due to Assumption \ref{assumption:controllable}, $A$ is full-rank. Therefore, for $i \in \Nplayers$,
        $B^{i\transpose}P_{t+1}^{i} = B^{i\transpose}\bar{P}_{t+1}$.
    Thus,
        $\bar{R}_{t} = 
        \begin{bmatrix}
            [R_{t}^{1}]_{11} & \cdots & [R_{t}^{1}]_{1N}\\
            \vdots & \ddots\\
            [R_{t}^{N}]_{N1} & \cdots & [R_{t}^{N}]_{NN}
        \end{bmatrix}$.
    The proof is complete in light of \eqref{eq:positiveR} (Assumption \ref{assumption:bounds}).
\end{proof}

\begin{remark}
    Based on the proof above, for any given $\tau$ and $t$, such that $1\leq \tau \leq t \leq T-1$, 
        $\bar{R}_{\tau|t} = \bar{R}_{\tau}$.
\end{remark}

\begin{lemma}\label{lemma:matrixK}
    Suppose $m \leq n$ and $R\in \mathbb{S}^{m}_{++}$. 
    If $P\in \mathbb{S}^{n}_{++}$, then for any given $B$ that has appropriate size and finite singular values, all singular values of matrix $K = (R+B^{\transpose}PB)^{-1}B^{\transpose}P$ satisfy the inequality
$  0 \leq \sigma_{k}(K) < \theta_{k}$,
    where $\sigma_{k}(\cdot)$ is the $k$-th singular value of its argument such that $\sigma_{1}(\cdot) \geq \cdots \geq \sigma_{m}(\cdot)$, and $\sigma_{\min}(B) < \theta_{k} <\sigma_{\max}(B)$.
\end{lemma}
\begin{proof}
    Due to matrix $K^{\transpose}K$ being symmetric and all elements are real, all eigenvalues of $K^{\transpose}K$ are real.
    Define an $n\times n$ matrix
        $\underbar{B} := 
        \begin{bmatrix}
            B & 0_{n\times n-m}
        \end{bmatrix}$,
    and suppose
    \begin{equation*}
        \lambda_{1}(B^{\transpose}K^{\transpose}KB) \geq \cdots \geq \lambda_{m}(B^{\transpose}K^{\transpose}KB).
    \end{equation*}
    Note that $       0 =  \lambda_{m+1}(B^{\transpose}K^{\transpose}KB) = \cdots = \lambda_{n}(B^{\transpose}K^{\transpose}KB)$,
    due to $\textit{rank}(B^{\transpose}K^{\transpose}KB) \leq m$.
    By using \cite[Theorem 4.5.9]{horn_matrix_2013} (see also the discussion on \cite[p.~284]{horn_matrix_2013}), for any $k$ such that $1\leq k\leq m\leq n$,  where $\textit{dim}(B)=m$,
    we have that
    \begin{align*}
        \lambda_{k}(B^{\transpose}K^{\transpose}KB) &= \lambda_{k}(\underbar{B}^{\transpose}K^{\transpose}K\underbar{B})= \theta_{k}\lambda_{k}(K^{\transpose}K),
    \end{align*}
    where $0\leq \theta_{k} \leq \sigma_{max}(\underbar{B})=\sigma_{max}(B)$.
    Due to
    \begin{align*}
        \sigma_{k}(KB) &= \sigma_{k}((R+B^{\transpose}PB)^{-1}B^{\transpose}PB)\\
        &= \sigma_{k}\bigg((I - (R+B^{\transpose}PB)^{-1}R) \bigg),
    \end{align*}
    and
       $0 \leq \sigma_{k}\bigg((I - (R+B^{\transpose}PB)^{-1}R) \bigg) < 1$,
    when $P \in \mathbb{S}_{++}^{n}$. This is due to the following. Consider a scalar $\sigma$ and matrix
    \begin{align*}
        &G := (I-(\tempRBP)^{-1}R)^{\transpose}(I-(\tempRBP)^{-1}R) - (1-\sigma) I \\
        &= \sigma I - R(\tempRBP)^{-1} \\
        &\quad - (\tempRBP)^{-1}R + R(\tempRBP)^{-1}(\tempRBP)^{-1}R\\
        &= R\bigg(\sigma R^{-2}- (\tempRBP)^{-1}R^{-1} - R^{-1}(\tempRBP)^{-1}\\
        &\quad + (\tempRBP)^{-1}(\tempRBP)^{-1} \bigg)R\\
        &= R(\tempRBP)^{-1}\bigg(\sigma(\tempRBP)R^{-1}R^{-1}(\tempRBP) \\
        &\quad - R^{-1}(\tempRBP) - (\tempRBP)R^{-1} + I \bigg)(\tempRBP)^{-1}R\\
        &= R(\tempRBP)^{-1}\bigg(\sigma(I+B^{\transpose}PBR^{-1})(I+R^{-1}B^{\transpose}PB)\\
        &\quad  - R^{-1}(\tempRBP) - (\tempRBP)R^{-1} + I \bigg)(\tempRBP)^{-1}R\\
        &= R(\tempRBP)^{-1}\bigg((\sigma-1)(I+B^{\transpose}PBR^{-1}+R^{-1}B^{\transpose}PB)\\
        &\quad  + \sigma(B^{\transpose}PBR^{-1}R^{-1}B^{\transpose}PB)\bigg)(\tempRBP)^{-1}R.
    \end{align*}
    Therefore, if $\det(G) = 0$, then there exist zero eigenvalue of $(\sigma-1)(I+B^{\transpose}PBR^{-1}+R^{-1}B^{\transpose}PB) + \sigma(B^{\transpose}PBR^{-1}R^{-1}B^{\transpose}PB)$.

    Since $B^{\transpose}PBR^{-1}R^{-1}B^{\transpose}PB = (R^{-1}B^{\transpose}PB)^{\transpose}(R^{-1}B^{\transpose}PB)(:= G^{'})$, therefore
        $\lambda_{k}(B^{\transpose}PBR^{-1}R^{-1}B^{\transpose}PB) \geq 0$, $k\in  \mathbb{N}_m$.
    Moreover, Let $\bar{G} := I+B^{\transpose}PBR^{-1}+R^{-1}B^{\transpose}PB$, 
    Suppose $\lambda_{1}(\bar{G}) \geq \cdots \geq \lambda_{m}(\bar{G})$. By Weyl's inequality, for $ k \in \mathbb{N}_m$, we have
    \begin{equation}\label{eq:eigenStep3}
        \lambda_{k}(I) + \lambda_{m}(B^{\transpose}PBR^{-1}+R^{-1}B^{\transpose}PB) \leq \lambda_{k}(\bar{G}).
    \end{equation}
    
    By applying Weyl's inequality again, and due to 
    \begin{align*}
        B^{\transpose}PBR^{-1} = R^{\frac{1}{2}}(R^{-\frac{1}{2}}B^{\transpose}PBR^{-\frac{1}{2}})R^{\frac{1}{2}},
    \end{align*}
    we have all eigenvalues of $B^{\transpose}PBR^{-1}$ are greater than 0. Similarly to $R^{-1}B^{\transpose}PB$.
    Therefore,
    \begin{equation}\label{eq:eigenStep4}
        0 < 1 \leq \lambda_{k}(I) + \lambda_{m}(B^{\transpose}PBR^{-1})+\lambda_{m}(R^{-1}B^{\transpose}PB) \leq \lambda_{k}(\bar{G}).
    \end{equation}

     We can further conclude that
     \begin{align*}
         (\sigma-1)\lambda_{k}(G^{'})+\sigma\lambda_{m}(\bar{G}) \leq \lambda_{k}(G) \leq (\sigma-1)\lambda_{k}(G^{'})+\sigma\lambda_{1}(\bar{G}).
     \end{align*}
     If $\sigma \geq 1$, due to
     \begin{align*}
         (\sigma-1)\lambda_{k}(G^{'})+\sigma\lambda_{m}(\bar{G}) \leq \lambda_{k}(G) \leq (\sigma-1)\lambda_{k}(G^{'})+\sigma\lambda_{1}(\bar{G}),
     \end{align*}
     we have $(\sigma-1)\lambda_{k}(G^{'})+\sigma\lambda_{m}(\bar{G}) > 0$,
     therefore $\lambda_{k}(G) > 0(k \in \mathbb{N}_{n})$. If $\sigma < 0$, $(\sigma-1)\lambda_{k}(G^{'})+\sigma\lambda_{m}(\bar{G}) < 0$ and $\lambda_{k}(G) \leq (\sigma-1)\lambda_{k}(G^{'})+\sigma\lambda_{1}(\bar{G}) < 0$.
     
     Therefore $\lambda_{k}(G) < 0$, $k \in \mathbb{N}_{n})$. Thus, $0 \leq \sigma < 1$.
    Consequently, all singular values of matrix $I - (R+B^{\transpose}PB)^{-1}R$ are between 0 and 1. Hence,
        $0 \leq \sigma_{k}(K) < \theta_{k}$, for $k \in \mathbb{N}_{n}$.
\end{proof}

\begin{corollary}\label{corrolary:boundedK}
    Suppose the cost matrices $(Q_{t})_{t=1}^{T}$ and $(R_{t}^{i})_{t=1,i=1}^{T-1,N}$ satisfy the conditions described from Equation \eqref{eq:costFPDG1} to \eqref{eq:costFPDG3} and Assumption \ref{assumption:bounds}.
    For a given preview horizon $W\in \mathbb{N}_{T-1}$, define
    \begin{equation}
        Q_{\tau|t}:= 
        \begin{cases}
            Q_{\tau} \text{ if $1\leq \tau \leq t+W$}\\
            Q_{t+W} \text{ if $t+W < \tau \leq T$},
        \end{cases}
    \end{equation}
    and
    \begin{equation}
        R_{\tau|t}^{i}:= 
        \begin{cases}
            R_{\tau}^{i} \text{ if $1\leq \tau \leq t+W$}\\
            R_{t+W}^{i} \text{ if $t+W < \tau \leq T$},
        \end{cases}
    \end{equation}
    for $i = \Nplayers$.
    There exists a scalar $\omega_{K}$ such that
        $\|K_{\tau|t}\| \leq \omega_{K}$,
    for $1\leq \tau,t\leq T$.
\end{corollary}

\begin{proof}
    This can be directly concluded by letting $\omega_{K} = \sigma_{max}(B)\sigma_{max}(A)$ and applying Lemma \ref{lemma:matrixK}.
\end{proof}

\begin{corollary}\label{corollary:positiveQ}
    For any given $\tau,t\in\mathbb{N}_{T-1}$, 
       $ \bar{Q}_{\tau|t} = Q_{\tau|t} + K_{\tau|t}^{\transpose}(R_{\tau|t}^{1} - \bar{R}_{\tau|t})K_{\tau|t} \in \mathbb{S}^{n}_{++}$.
\end{corollary}
\begin{proof}
    Suppose
    \begin{align*}
        &\lambda_{1}(Q_{\tau|t}) \geq \cdots \geq \lambda_{n}(Q_{\tau|t}),\\
        &\lambda_{1}(K_{\tau|t}^{\transpose}(R_{\tau|t}^{1} - \bar{R}_{\tau|t})K_{\tau|t}) \geq \cdots \geq \lambda_{n}(K_{\tau|t}^{\transpose}(R_{\tau|t}^{1} - \bar{R}_{\tau|t})K_{\tau|t}),\\
        &\lambda_{1}(R_{\tau|t}^{1} - \bar{R}_{\tau|t}) \geq \cdots \geq \lambda_{n}(R_{\tau|t}^{1} - \bar{R}_{\tau|t}).
    \end{align*}
    By Weyl's inequality,
    \begin{align*}
        \lambda_{min}(\bar{Q}_{\tau|t}) = \lambda_{n}(\bar{Q}_{\tau|t})\geq \lambda_{n}(Q_{\tau|t}) + \lambda_{n}(K_{\tau|t}^{\transpose}(R_{\tau|t}^{1} - \bar{R}_{\tau|t})K_{\tau|t}).
    \end{align*}
    By \cite[Theorem 4.5.9]{horn_matrix_2013}, there exists a positive scalar $\theta_{n}$ such that
        $\lambda_{n}(K_{\tau|t}^{\transpose}(R_{\tau|t}^{1} - \bar{R}_{\tau|t})K_{\tau|t}) = \theta_{n}\lambda_{min}(R_{\tau|t}^{1} - \bar{R}_{\tau|t})$,
    where $\sigma_{min}(K_{\tau|t}) \leq \theta_{n} \leq \sigma_{max}(K_{\tau|t}) < \sigma_{max}(B)$.
    The last inequality is due to Lemma \ref{lemma:matrixK}. 
    Moreover,
    \begin{align*}
        \max(0, \sigma_{max}(\contB)\lambda_{max}(\bar{R}_{t}-R_{t}^{1})) > -\lambda_{min}(K_{\tau|t}^{\transpose}(R_{t}^{1}-\bar{R}_{t})K_{\tau|t}).
    \end{align*}
    Thus, by Assumption \ref{assumption:lowerQ} and Corollary \ref{corollary:boundedR}, we have
    \begin{align*}
    0 &<  \lambda_{min}(Q_{\tau|t}) -\max(0,\sigma_{max}(\contB)\lambda_{max}(\mathbf{R}_{t}))\\
    &=\lambda_{min}(Q_{\tau|t}) - \max(0, \sigma_{max}(\contB)\lambda_{max}(\bar{R}_{t}-R_{t}^{1})) \\
    &< \lambda_{min}(Q_{\tau|t}+K_{t}^{\transpose}(R_{\tau|t}^{1}-\bar{R}_{\tau|t})K_{\tau|t})= \lambda_{min}(\bar{Q}_{\tau|t}).
    \end{align*}
    % \lambda_{min}(\bar{Q}_{\tau|t}) &= \lambda_{min}(Q_{\tau|t}+K_{t}^{\transpose}(R_{\tau|t}^{1}-\bar{R}_{\tau|t})K_{\tau|t})
         % &>\lambda_{min}(Q_{\tau|t}) - \max(0,\sigma_{B}\lambda_{min}(R_{\tau|t}^{1} - \bar{R}_{\tau|t}))
    % Moreover,
    % \begin{align*}
    %     \theta_{n}\lambda_{min}(R_{\tau|t}^{1} - \bar{R}_{\tau|t}) \geq \max(0,\sigma_{B}\lambda_{min}(R_{\tau|t}^{1} - \bar{R}_{\tau|t})).
    % \end{align*}
    % Thus, 
    % \begin{align*}
    %     \lambda_{min}(\bar{Q}_{\tau|t}) &= \lambda_{min}(Q_{\tau|t}+K_{t}^{\transpose}(R_{\tau|t}^{1}-\bar{R}_{\tau|t})K_{\tau|t}) \\
    %     &> \lambda_{min}(Q_{\tau|t}) +\max(0,\sigma_{B}\lambda_{min}(R_{\tau|t}^{1} - \bar{R}_{\tau|t})) > 0.
    % \end{align*}
    Therefore, $\bar{Q}_{\tau|t}$ is positive definite for all $t,\tau \in \mathbb{N}_{T}$.
\end{proof}

\begin{remark}
    Assumption \ref{assumption:lowerQ} suggests that, if the distance between the cost matrices $R_{t}^{2}$ and $R_{t}^{1}$ is sufficiently small, or $R_{t}^{1}$ is a dominant cost than $R_{t}^{2}$, then matrix $Q_{\tau|t}$ are positive definite. This will help us to develop the contraction between $K_{\tau|t}$ and $K_{\tau|t_{0}}$ for $\tau \in \mathbb{N}_t$ and $t_{0} \in \mathbb{N}_{T-1}$.
\end{remark}
\begin{assumption}\label{assumption:potentialRepeat}
    The LQDFG with parameters $\{Q_{\tau|t}\}_{\tau=1}^{T}$ and $\{R_{\tau|t}\}_{\tau=1}^{T-1}$ is an LQDFPG for all $t\in \mathbb{N}_{T}$.
\end{assumption}
The assumption above ensures that $\text{DFLGame}(\bar{\mathcal{H}}_{t},T)$ is a LQDFPG. The performance of the proposed Algorithm can be characterised similar to the case of optimal control. {\color{red} this sounds like all the analysis is trying to suit with my method. Also, as an assumption, i think this should be put below assumption 3.}
\begin{lemma}\label{lemma:boundedP}
Let $\bar{P}_{T} = \bar{Q}_{T}$ and 
    \begin{align*}
        \bar{K}_{t}& = -(R_{t}+ B^{\transpose}\bar{P}_{t+1}B)^{-1}B^{\transpose}\bar{P}_{t+1},\\
        \bar{P}_{t}& = \bar{Q}_{t} + \bar{K}_{t}^{\transpose}\bar{R}_{t}\bar{K}_{t} + (A+B\bar{K}_{t})^{\transpose}\bar{P}_{t+1}(A+B\bar{K}_{t}),
    \end{align*}
    for $t \in \mathbb{N}_{T-1}$. There exist positive definite matrices $\bar{P}_{min}$ and $\bar{P}_{max}$ such that $
        \bar{P}_{min} \preceq \bar{P}_{t} \preceq \bar{P}_{max}$.
\end{lemma}
\begin{proof}
    By Corrollary \ref{corrolary:boundedK} and Assumption \ref{assumption:lowerQ}, there exist positive definite matrices $\bar{Q}_{min},\bar{Q}_{max}$ such that $
        \bar{Q}_{min} \preceq \bar{Q}_{t} \preceq \bar{Q}_{max}$,
    for $t\in\mathbb{N}_{T}$.
    This, together with the Assumption \ref{assumption:bounds} and following a similar procedure to the proof of \cite[Proposition 11]{zhang_regret_2021} complete the proof.
\end{proof}


\begin{lemma}\label{lemma:m}
    For $T,S,V_{1},V_{2}\in \mathbb{S}_{++}^{n}$, if
$       m \geq 1+\frac{\lambda_{max}(V_{1}-V_{2})}{\lambda_{min}(T+V_{2})}$,
    then for any non-zero $x$, we have
    \begin{equation}
        \frac{\quadinner{T+V_{1}}}{\quadinner{S+V_{2}}} \leq m\frac{\quadinner{T+V_{2}}}{\quadinner{S+V_{2}}}
    \end{equation}
\end{lemma}
\begin{proof}
    For any nonzero $x$, we have
    \begin{align*}
        m \geq 1+\frac{\lambda_{max}(V_{1}-V_{2})}{\lambda_{min}(T+V_{2})}
        \geq 1+ \frac{\quadinner{V_{1}-V_{2}}}{\quadinner{T+V_{2}}}
        = \frac{\quadinner{T+V_{1}}}{\quadinner{T+V_{2}}}.
     \end{align*}
     Due to $\quadinner{S+V_{2}} > 0$ and the fact that $T,V_{2},V_{1}$ are positive definite, we have that 
         $m\frac{\quadinner{T+V_{2}}}{\quadinner{S+V_{2}}} \geq \frac{\quadinner{T+V_{1}}}{\quadinner{S+V_{2}}}$.
\end{proof}


\begin{definition}
    For any $X,Y\in \mathbb{S}_{++}^{n}$, define the operator $\delta_{\infty}(\cdot, \cdot)$ as
  $ \delta_{\infty}(X, Y) := \| \log(Y^{-\frac{1}{2}}XY^{-\frac{1}{2}})\|_{\infty}$, where $\|\cdot\|_{\infty}$ denotes the matrix infinity-norm.
        % \delta_{\infty}(X, Y) := (\sum_{i=1}^{d} \log^{2}(\lambda_{i}))^{\frac{1}{2}},
    % where $\lambda_{1},\cdots, \lambda_{d}$ are the eigenvalues of the matrix $XY^{-1}$.
\end{definition}

\begin{proposition}\label{proposition:deltaRatio}
    For any $X,Y\in \mathbb{S}_{++}^{n}$,
$ \delta_{\infty}(X,Y) = \max(\log(\sup_{\xi\neq0} \frac{\xi^{\transpose}X\xi}{\xi^{\transpose}Y\xi},\log(\sup_{\xi\neq0} \frac{\xi^{\transpose}Y\xi}{\xi^{\transpose}X\xi})$).
\end{proposition}
\begin{proof}
    Suppose matrices $X,Y\in\mathbb{S}_{++}^{n}$. From \cite[Remark 2.2.]{lee_invariant_2008}, $\delta_{\infty}(X,Y) = \max(\lambda_{max}(Y^{-1}X),\lambda_{max}(XY^{-1})), = \max(\log(\sup_{\xi\neq0} \frac{\xi^{\transpose}X\xi}{\xi^{\transpose}Y\xi}),\log(\sup_{\xi\neq0} \frac{\xi^{\transpose}Y\xi}{\xi^{\transpose}X\xi}))$.
\end{proof}

\begin{remark}\label{remark:delta}
    For $T,S,V_{1},V_{2}\in \mathbb{S}_{++}^{n}$, without loss of generality, assume
    $\sup_{x\neq 0} \frac{\quadinner{T+V_{1}}}{\quadinner{S+V_{2}}} \geq 1$.
    Based on Lemma \ref{lemma:boundedP},\ref{lemma:m} and Proposition \ref{proposition:deltaRatio}, suppose a positive scalar $m$ satisfies
    \begin{align*}
        m \geq 1+\frac{\lambda_{max}(V_{1}-V_{2})}{\lambda_{min}(T+V_{2})}.
    \end{align*}
   Consequently, 
    \begin{align*}
        \delta_{\infty}(T+V_{1},S+V_{2}) &= \log( \sup_{x\neq 0} \frac{\quadinner{T+V_{1}}}{\quadinner{S+V_{2}}})\\
        &\leq \log(\sup_{x\neq 0} \frac{\quadinner{T+V_{1}}}{\quadinner{S+V_{2}}})\\
        &\leq \log(m)+\log(\sup_{x\neq 0} \frac{\quadinner{T+V_{2}}}{\quadinner{S+V_{2}}})\\
        &\leq \log(m) + \delta_{\infty}(T+V_{2},S+V_{2})\\
        &\leq \log(m) + \gamma\delta_{\infty}(T,S),
    \end{align*}
    where $\gamma$, $0<\gamma<1$, can be found by \cite[Lemma D.2]{krauth_finite-time_2019}.
\end{remark}

\begin{lemma}\label{lemma:boundedPK}
    Suppose the preview window length is given by a non-negative integer $W\in \mathbb{N}_{T-1}$. For any $\tau$, $t$, and $t_{0}$ such that $1\leq \tau\leq t\leq t_{0}\leq T$, there exist positive scalars $\gamma,\varepsilon_{P},\varepsilon_{K},C_{P},C_{K}^{'}$ with $\gamma \in (0,1)$, such that
    \begin{equation*}
        \|\bar{P}_{\tau|t}-\bar{P}_{\tau|t_{0}}\| \leq C_{P}\gamma^{t-\tau+W}+\varepsilon_{P},
    \end{equation*}
    and
        $\|\bar{K}_{\tau|t}-\bar{K}_{\tau|t_{0}}\| \leq C_{K}^{'}\gamma^{t-\tau+1+W}+\varepsilon_{K}^{'}$.
\end{lemma}
\begin{proof}
     For any $\tau$ ,$t$, $t_{0}$ where $1\leq \tau\leq t\leq t_{0}\leq T$, 
     let
     \begin{align*}
        &\alpha_{\tau,t} := \lambda_{max}(A^{\transpose}(\bar{P}_{\tau+1|t}^{-1}+B\bar{R}_{\tau|t}^{-1}B^{\transpose})^{-1}A)\\
        &\beta_{\tau,t} := \lambda_{min}(\bar{Q}_{\tau|t})\\ 
        &\gamma := \max_{1\leq \tau,t \leq T} \frac{\alpha_{\tau,t}}{\alpha_{\tau,t}+\beta_{\tau,t}}. 
     \end{align*}
     By \cite[Lemma D.2]{krauth_finite-time_2019}, Lemmas \ref{lemma:boundedP} and \ref{lemma:m}, and Remark \ref{remark:delta}, we have 
    \begin{align*}
        \delta_{\infty}(\bar{P}_{\tau|t},\bar{P}_{\tau|t_{0}}) &= \delta_{\infty}(\bar{Q}_{\tau|t}+A^{\transpose}(\bar{P}_{\tau+1|t}^{-1}+B\bar{R}_{\tau|t}^{-1}B^{\transpose})^{-1}A,\\
        & \qquad \bar{Q}_{\tau|t_{0}}+A^{\transpose}(\bar{P}_{\tau+1|t_{0}}^{-1}+B\bar{R}_{\tau|t_{0}}^{-1}B^{\transpose})^{-1}A)\\
        % &\leq \delta_{\infty}(Q_{\tau}+K_{\tau|t}^{\transpose}(R_{\tau}^{1}-\bar{R}_{\tau})K_{\tau|t}+A^{\transpose}(P_{\tau+1|t}^{-1}+B\bar{R}_{\tau|t}^{-1}B^{\transpose})^{-1}A,\\
        % & \qquad Q_{\tau}+K_{\tau|t_{0}}^{\transpose}(R_{\tau}^{1}-\bar{R}_{\tau})K_{\tau|t_{0}}+A^{\transpose}(P_{\tau+1|t_{0}}^{-1}+B\bar{R}_{\tau|t_{0}}^{-1}B^{\transpose})^{-1}A)\\
        &\leq \gamma\delta_{\infty}(\bar{P}_{\tau+1|t},\bar{P}_{\tau+1|t_{0}}) + \varepsilon_{1}\\
        &\leq \gamma^{t-\tau+W}\delta_{\infty}(\bar{P}_{t+W|t},\bar{P}_{t+W|t_{0}}) + \varepsilon_{1}\sum_{p=0}^{t-\tau+W}\gamma^{p}\\
        % &< \gamma^{t-\tau+W}\delta_{\infty}(\bar{P}_{t+W|t},\bar{P}_{t+W|t_{0}}) + \frac{\varepsilon_{1}}{1-\gamma}\\
        &\leq C_{P_{1}}\gamma^{t-\tau+W}+\frac{\varepsilon_{1}}{1-\gamma},
    \end{align*}
    where $\varepsilon_{1}$ can be found as similar as the term $\log(m)$ from Remark \ref{remark:delta}, and $C_{P1} = \max_{t\leq t_{0}} \delta_{\infty}(\bar{P}_{t|t},\bar{P}_{t|t_{0}})$ . 
    % By inequality
    %\begin{align*}
    %    \frac{e^{x}-1}{x} \leq \frac{e^{c}-1}{c},
    %\end{align*}
    %for $0 < x \leq c$. 
Let $h = \max_{(\tau,t_{0}| \tau,\leq t_{0})} \delta_{\infty}(\bar{P}_{\tau|t},\bar{P}_{\tau|t_{0}})$, we have
    \begin{equation*}
        \frac{exp(\delta_{\infty}(\bar{P}_{\tau|t},\bar{P}_{\tau|t_{0}}))-1}{\delta_{\infty}(\bar{P}_{\tau|t},\bar{P}_{\tau|t_{0}})} \leq \frac{exp(h)-1}{h}.
    \end{equation*}
    Thus,
    \begin{align*}
        \|\bar{P}_{\tau|t}-\bar{P}_{\tau|t_{0}}\| &\leq \lambda_{max}(\bar{P}_{\tau|t_{0}})\frac{\exp(h)-1}{h}\delta_{\infty}(\bar{P}_{\tau|t},\bar{P}_{\tau|t_{0}})\\
        &< C_{P}\gamma^{W}+\varepsilon_{P},
    \end{align*}
    where $C_{P} = \frac{C_{P1}\lambda_{max}(\bar{P}_{\tau|t_{0}})(\exp(h)-1)}{h}$ and $\varepsilon_{P} = \frac{\varepsilon_{1}\lambda_{max}(\bar{P}_{\tau|t_{0}})(\exp(h)-1)}{h(1-\gamma)}$. Following by similar steps of equations (20) and (21) from \cite[Lemma 8]{chen_regret_2023}, we can find $C_{K}^{'},\varepsilon_{K}^{'}(C_{K}^{'}>0,\varepsilon_{K}^{'}>0)$ we have that $\|\bar{K}_{\tau|t}-\bar{K}_{\tau|t_{0}}\| \leq C_{K}^{'}\gamma^{t-\tau-1+W}+\varepsilon_{K}^{'}$.
    % \begin{align*}
    %     \|\bar{K}_{\tau|t}-\bar{K}_{\tau|t_{0}}\| \leq C_{K}^{'}\gamma^{t-\tau-1+W}+\varepsilon_{K}^{'}.
    % \end{align*}
\end{proof}

\begin{remark}
    When $\tau = t$ and $t_{0} = T$, we have
    \begin{align*}
        \|\bar{K}_{t|t}-\bar{K}_{t}^{*}\| \leq C_{K}^{'}\gamma^{W-1} + \varepsilon_{K}^{'}.
    \end{align*}
\end{remark}

\begin{lemma}\label{lemma:multGain}
    Let positive integers $t_0$, $t_1$, $t$, and $T_1$ satisfy $1\leq t_{0} \leq t_{1}\leq t\leq T-1$. There exist positive scalars $C_{fb}$ and $\eta$ such that
    \begin{equation*}
        \left \| \prod_{\tau=t_{0}}^{t_{1}}(A+\mathbf{B}\bar{K}_{\tau|t})  \right\| \leq C_{fb}\eta^{t_{1}-t_{0}+1},\text{ and }0<\eta<1.
    \end{equation*}
\end{lemma}
This lemma can be proved following the same steps as those found in the proof of \cite[Appendix E,Proposition 2]{zhang_regret_2021}.
\begin{lemma}\label{lemma:distanceXt}
    Suppose the preview window horizon is given by a non-negative integer $W\in\mathbb{N}_{T-1}$, there exists . Moreover, let $\varepsilon_{K} := \|\contB\|\varepsilon_{K}^{'}$ and $C_{K} = \|\contB\|C_{K}^{'}$, where $C_{K}^{'}$ and $\varepsilon_{K}^{'}$ are as in Lemma \ref{lemma:boundedPK}. Then, there exists $q\in(0,1)$ such that
    \begin{equation*}
    \begin{split}
        \|x_{t}-x_{t|t}\| &\leq C_{fb}^{2}\|\bar{x}_{1}\|q^{t} \left [\frac{C_{K}\gamma^{W}}{\gamma-1}\bigg(\frac{1-(\frac{\eta\gamma}{q})^{t}}{1-\frac{\eta\gamma}{q}} - \frac{1-(\frac{\eta}{q})^{t}}{1-\frac{\eta}{q}} \bigg) \right .\\
        &\left . +\varepsilon_{K}\bigg(\frac{(t-1)(\frac{\eta}{q})^{t+1}-t(\frac{\eta}{q})^{t}+\frac{\eta}{q}}{(1-\frac{\eta}{q})^{2}}\bigg) \right ]  \end{split}
    \end{equation*}
    where $\gamma$ is given in Lemma~\ref{lemma:boundedPK} and $\eta$ is as in Lemma~\ref{lemma:multGain}.
\end{lemma}
\begin{proof}
    Suppose $N$ is a positive integer. For an arbitrary sequence $(a_{i})_{i=1}^{N}$. Suppose $e$ is the identity element for the sequence. For $1\leq p_{1},p_{2}\leq N$, define the product operator as
\begin{equation*}
    \prod_{j=p_{1}}^{p_{2}} a_{j} := 
    \begin{cases}
        a_{p_{2}}a_{p_{2}-1}\dots a_{p_{1}} & \text{if $p_{1} < p_{2}$}\\
        a_{p_{2}} & \text{if $p_{1} = p_{2}$}\\
        e & \text{if $p_{1} > p_{2}$},
    \end{cases}
\end{equation*}
Define $\omega_{t} := x_{t}-x_{t|t}$, $\theta_{\tau| p_{1},p_{2}} := x_{\tau|p_{1}}-x_{\tau|p_{2}}$, where $\tau \leq p_{1}\leq p_{2}\leq T$. Consequently, $w_{1} = 0$ and $\theta_{1|p_{1},p_{2}}=0$. We now investigate the dynamics of $w_{t}$ and $\theta_{\tau|p_{1},p_{2}}$. For integer $\tau > 1$:
\begin{align*}
    &\theta_{\tau|p_{1},p_{2}}= x_{\tau|p_{1}}-x_{\tau|p_{2}}\\
    &= (A+\sum_{j}^{N}B^{j}K_{j,\tau|p_{1}})x_{\tau-1|p_{1}} - (A+\sum_{j}^{N}B^{j}K_{j,\tau|p_{2}})x_{\tau-1|p_{2}}\\
    &= (A+\sum_{j}^{N}B^{j}K_{j,\tau|p_{1}})\theta_{\tau-1|p_{1},p_{2}} + [\sum_{j=1}^{N} B^{j}(K_{j,\tau-1|p_{1}}-K_{j,\tau-1|p_{2}})]x_{\tau-1|p_{2}}\\
    &\qquad \vdots\\
    &= \sum_{i=1}^{\tau-1}\bigg(\prod_{j=i+1}^{\tau-1}(A+\sum_{m=1}^{N}B^{m}K_{m,j|p_{1}})\bigg)\bigg[\sum_{m=1}^{N}B^{m}(K_{m,i|p_{1}}-K_{m,i|p_{2}})\bigg]x_{i|p_{2}}  \\
    &= \sum_{i=1}^{\tau-1}\bigg(\prod_{j=i+1}^{\tau-1}(A+\sum_{m=1}^{N}B^{m}K_{m,j|p_{1}})\bigg)\bigg[\sum_{m=1}^{N}B^{m}(K_{m,i|p_{1}}-K_{m,i|p_{2}})\bigg]\\
    &\qquad\bigg(\prod_{n=1}^{i-1} (A+\sum_{m=1}^{N}B^{m}K_{m|p_{2}})\bigg)\bar{x}_{1}\\
    &= \sum_{i=1}^{\tau-1}\bigg(\prod_{j=i+1}^{\tau-1}(A+\mathbf{B}\bar{K}_{j|p_{1}})\bigg)\bigg[\mathbf{B}^{\mathsf{T}}(\bar{K}_{j|p_{1}}^{\mathsf{T}}-\bar{K}_{j|p_{2}}^{\mathsf{T}})\bigg]\\
    &\qquad\bigg(\prod_{n=1}^{i-1}(A+\mathbf{B}\bar{K}_{n|p_{2}})\bigg)\bar{x}_{1}.
\end{align*}
Thus, for integer $t\in\mathbb{N}_T$, we have
\begin{align*}
    \omega_{t} &= x_{t} - x_{t|t}\\
    &= Ax_{t-1} + \sum_{j=1}^{N}B^{j}[K^{j}(x_{t-1}-x_{t-1|t-1})+K_{t-1|t-1}^{j}x_{t-1|t-1}] - x_{t|t}\\
    &= (A+\sum_{j=1}^{N}B^{j}K^{j})x_{t-1} + [\sum_{j=1}^{N}B^{j}(K_{t-1|t-1}^{j}-K^{j})]x_{t-1|t-1} - x_{t|t}\\
    &= (A+\sum_{j=1}^{N}B^{j}K^{j})(x_{t-1}-x_{t-1|t-1}) + x_{t|t-1}-x_{t|t}\\
    &= \sum_{i=1}^{t} (A+\sum_{j=1}^{N}B^{j}K^{j})^{t-i} \theta_{i|i-1,i}.
\end{align*}

We now investigate the dynamics of $\theta_{\tau|p_{1},p_{2}}$. Note that $\theta_{0|p_{1},p_{2}} = 0$, and 
\begin{align*}
    \theta_{\tau+1|p_{1},p_{2}} &= x_{\tau+1|p_{1}} - x_{\tau+1|p_{2}}\\
    &= (A+\BK{\tau|p_{1}})x_{\tau|p_{1}}-(A+\BK{\tau|p_{2}})x_{\tau|p_{2}}\\
    &= (A+\BK{\tau|p_{1}})(\theta_{\tau|p_{1},p_{2}}+x_{\tau|p_{2}})-(A+\BK{\tau|p_{2}})x_{\tau|p_{2}}\\
    &= (A+\BK{\tau|p_{1}})\theta_{\tau|p_{1},p_{2}} + \mathbf{B}(\bar{K}_{\tau|p_{1}}-\bar{K}_{\tau|p_{2}})x_{\tau|p_{2}}.
\end{align*}
This implies that
\begin{align*}
    x_{\tau+1|p_{1}} - x_{\tau+1|p_{2}} &= \sum_{n=1}^{\tau}\bigg(\prod_{m=n+1}^{\tau}(A+\BK{m|p_{1}})\bigg)\mathbf{B}(\bar{K}_{n|p_{1}}-\bar{K}_{n|p_{2}})\\
        &\qquad \bigg(\prod_{m=1}^{n-1}(A+\BK{m|p_{1}})\bigg)\bar{x}_{1}.
\end{align*}
By Lemma \ref{lemma:multGain}, we can bound the product term by
\begin{equation*}
    \| \prod_{m=n+1}^{\tau}(A+\BK{m|p_{1}})\| \leq C_{fb}\eta^{\tau-n},
\end{equation*}
By Lemma \ref{lemma:boundedPK}, let $C_{K} := \|\mathbf{B}\|C_{K}^{'}$ and $\varepsilon_{K} := \|\mathbf{B}\|\varepsilon_{K}^{'}$, we have
\begin{equation*}
    \|\mathbf{B}(\bar{K}_{n|p_{1}}-\bar{K}_{n|p_{2}})\| \leq C_{K}\gamma^{p-n+W}+\varepsilon_{K}.
\end{equation*}
Thus,
\begin{align*}
    \|\theta_{\tau+1|p_{1},p_{2}}\| &= \|x_{\tau+1|p_{1}}-x_{\tau+1|p_{2}}\|\\
    &\leq C_{fb}^{2}\|\bar{x}_{1}\|(\sum_{n=1}^{\tau}\eta^{\tau}(C_{K}\gamma^{p-n}+\varepsilon_{K}))\\
    &= C_{fb}^{2}[\frac{C_{K}\gamma^{p+W}\eta^{\tau}}{1-\frac{1}{\gamma}}(1-(\frac{1}{\gamma})^{\tau+1})+ \varepsilon_{K}\tau\eta^{\tau}].
\end{align*}
Choosing $\tau = t,p_{1} = t$ and $p_{2} = T$, this results in
\begin{align*}
    \|\theta_{t|t,T}\| &\leq C^{2}_{fb}\|\bar{x}_{1}\|[\frac{C_{K}\gamma^{t+W}\eta^{t}}{1-\frac{1}{\gamma}}(1-(\frac{1}{\gamma})^{t+1}) + \varepsilon_{K}t\eta^{t}]\\
    &= C^{2}_{fb}\|\bar{x}_{1}\|[\frac{C_{K}\gamma^{1+W}\eta^{t}}{\gamma-1}(\gamma^{t}-1) + \varepsilon_{K}t\eta^{t}].
\end{align*}

Moreover,

\begin{align*}
    \|\theta_{i|i-1,i}\| \leq C_{fb}^{2}\|\bar{x}_{1}\|[\frac{C_{K}\eta^{i-1}\gamma^{W}}{\gamma-1}(\gamma^{i}-1) + \varepsilon_{K}(i-1)\eta^{i-1}].
\end{align*}
Similar to the argument following \cite[Lemma 10, (25)]{chen_regret_2023}, we can find $q,C_{q}\text{ }(C_{q}>0,0<q<1)$ such that $\|(A+\mathbf{B}\bar{K})^{t-i}\| \leq C_{q}q^{t-i}$. Conclude the above, we have
\begin{align*}
    &\|x_{t}-x_{t|t}\| \leq \sum_{\tau=1}^{t}\|(A+\mathbf{B}\bar{K})^{t-i}\theta_{i|i-1,i}\|\\
    &\leq C_{fb}^{2}C_{q}\|\bar{x}_{1}\|\sum_{i=1}^{t}q^{t-i}[\frac{C_{K}\eta^{i-1}\gamma^{W}}{\gamma-1}(\gamma^{i}-1) + \varepsilon_{K}(i-1)\eta^{i-1}]\\
    &= C_{fb}^{2}\|\bar{x}_{1}\|q^{t}[\frac{C_{K}\gamma^{W}}{\gamma-1}\bigg(\frac{1-(\frac{\eta\gamma}{q})^{t}}{1-\frac{\eta\gamma}{q}} - \frac{1-(\frac{\eta}{q})^{t}}{1-\frac{\eta}{q}} \bigg)\\
    &\qquad+\varepsilon_{K}\bigg(\frac{(t-1)(\frac{\eta}{q})^{t+1}-t(\frac{\eta}{q})^{t}+\frac{\eta}{q}}{(1-\frac{\eta}{q})^{2}}\bigg)]
\end{align*}
% Thus,
% \begin{align*}
%     \|x_{t}-x_{t}^{*}\| \leq 
% \end{align*}
\end{proof}

Before presenting the Cost Difference Lemma that is essential for the proof of Theorem~\ref{thm:main}, we introduce the following notation.

Suppose $\{\pi_{i,t}\}_{i=1,t=1}^{N,T-1}$,$\{\tilde{\pi}_{i,t}\}_{i=1,t=1}^{N,T-1}$ are policies that map $\mathbb{R}^{n}$ to $\mathbb{R}^{m}$. We state the convension $\bar{\pi}_{t}^{t_{0}} := \{\pi_{i,\tau}\}_{i=1,\tau=t}^{N,t_{0}}$ for the indices $i,t$.
We again define $x_{t+1}^{\bar{\pi}_{t}^{t+1}}(x_{t}):= Ax_{t} + \sum_{i=1}^{N} B^{i}\pi_{i,t}(x_{t})$,
\begin{align*}
&g_{i,t}(x_{t}, (u_{i,t})_{i=1}^{N}) := g_{i,t}(x_{t}, \mathbf{u}_{t}),\\
    \begin{split}
        &V_{i,T,t}^{\bar{\pi}_{t}^{T-1}}(x_{t}) := \\
        &\begin{cases}
            g_{i,T}(x_{T}^{\bar{\pi}_{T-1}^{T}}(x_{T-1}))+\sum_{l=0}^{T-t} g_{i,t+l}(x_{t+1+l}^{\bar{\pi}_{t+l}^{t+l+1}}(x_{t+l}),\\
            \qquad (\pi_{i,t+l}(x_{t+l}))_{i=1}^{N}) & \text{$1 \leq t \leq T$}\\
            $0$ & \text{$t > T$},
        \end{cases}
    \end{split}
    \\
    &Q_{i,T,t}^{\bar{\pi}_{t}^{T-1}}(x_{t},(u_{i,t})_{i=1}^{N}) := g_{t}(x_{t},(u_{i,t})_{i=1}^{N}) + V_{i,T,t+1}^{\bar{\pi}_{t+1}^{T-1}}(x_{t+1}^{\bar{\pi}_{t+1}^{T-1}}).
\end{align*}
Now we present our Cost Difference Lemma.

\begin{lemma}[Cost Difference Lemma]\label{lemma:costDifference}
For positive integer $T$, suppose for $t$ and $i$ satisfy $1 \leq t \leq T$ and $i = \Nplayers$. Let 
$\{\pi_{i,t}\}_{i=1,t=1}^{N,T-1}$,$\{\tilde{\pi}_{i,t}\}_{i=1,t=1}^{N,T-1}$ are policies that map $\mathbb{R}^{n}$ to $\mathbb{R}^{m}$, we have the following equality,

\begin{align*}
    &J_{i,T}(\{x_{t}\}_{t=1}^{T},(u_{i,t})_{i=1,t=1}^{N,T-1}) - J_{i,T}(\{\tilde{x}_{t}\}_{t=1}^{T},(\tilde{u}_{1,t})_{i=1,t=1}^{N,T-1})\\
    &= \sum_{t=1}^{T} Q_{i,T,t}^{\bar{\pi}_{t}^{T}}(x_{t},(u_{i,t})_{i=1}) -  V_{i,T,t}^{\bar{\pi}_{t}^{T}}(x_{t}),
\end{align*}
where $\tilde{x}_{t+1} = \tilde{x}_{t+1}^{\bar{\pi}_{t}^{t+1}}(\tilde{x}_{t})$, $\tilde{x}_{1} = x_{1}$ and $x_{t+1},(u_{i,t})_{i=1}^{N}$ satisfy \eqref{eq:linsys}.
\end{lemma}

\begin{proof}
\begin{align*}
    &\sum_{t=1}^{T-1} Q_{i,T,t}^{\bar{\pi}_{t}^{T-1}}(x_{t},(u_{i,t})_{i=1}^{N}) -  V_{i,T,t}^{\bar{\pi}_{t}^{T-1}}(x_{t}) \\
    &= \sum_{t=1}^{T-1} g_{t}(x_{t},(u_{i,t})_{i=1}^{N})+ V_{i,T,t+1}^{\bar{\tilde{\pi}}_{t+1}^{T-1}}(x_{t+1})-V_{i,T,t}^{\bar{\tilde{\pi}}_{t}^{T-1}}(x_{t})\\
    &= \underbrace{g_{T}(x_{T}) + \sum_{t=1}^{T-1} g_{t}(x_{t},(u_{i,t})_{i=1}^{N})}_{J_{i,T}(\{x_{t}\}_{t=1}^{T},\{(u_{i,t})_{i=1}^{N}\}_{t=1}^{T-1})} - V_{i,T,1}^{\bar{\tilde{\pi}}_{1}^{T-1}}(x_{1})\\
    &= J_{i,T}(\{x_{t}\}_{t=1}^{T},(u_{i,t})_{i=1,t=1}^{N,T-1}) - J_{i,T}(\{\tilde{x}_{t}\}_{t=1}^{T},(\tilde{u}_{i,t})_{i=1,t=1}^{N,T-1}).
\end{align*}
\end{proof}


\begin{proposition}\label{corollary:Delta}
    There exist positive scalars $\Delta_{1}$ and $\Delta_{2}$, such that
    \begin{align}
    \label{eq:delta1}
        &\|R_{t}^{i}+\mathbf{B}^{\transpose}P_{t+1}^{i}\mathbf{B}\| \leq \Delta_{1},\\
        \label{eq:delta2}
        &\|(R_{t}^{i}+\mathbf{B}^{\transpose}P_{t+1}^{i}\mathbf{B})\bar{K}_{t}^{*}+\mathbf{B}^{\transpose}P_{t+1}^{i}A\| \leq \Delta_{2},
    \end{align}
    for $i \in \Nplayers, t\in \mathbb{N}_{T-1}$.
\end{proposition}
\begin{proof}
    If costs $\{R_{t}^{i}\}_{i=1,t=1}^{N,T-1}$ and $\{Q_{t}\}_{t=1}^{N,T}$ from LQDFG is an LQDFPG. By Lemma \ref{lemma:gamePGrelation}, there exists a scalar $\Delta^{'}$ that is independent of $t$ and $i$, which $
        \|\contB^{\transpose}P_{t+1}^{i}\| = \|\contB^{\transpose}\bar{P}_{t+1}\| \leq \Delta^{'}$. 
    Due to Assumption \ref{assumption:bounds}, matrix $\|R_{t}^{i}\|$ is upperbounded uniformly w.r.t. $t$ and $i$. Thus we can find such $\Delta_{1}$ and $\Delta_{2}$ to satisfy  \eqref{eq:delta1} and \eqref{eq:delta2}.
\end{proof}
We have established all essential auxiliary lemmas and we can now use them to proof Theorem~\ref{thm:main}.
\subsection{Proof of Theorem~\ref{thm:main}}
We can now proof Theorem~\ref{thm:main} by using the above auxiliary lemmas.
Let $\{\pi_{i,t}\}_{i=1,t=1}^{N,T-1}$ be the control policies given in \eqref{eq:policy}, and $\{\tilde{\pi}_{i,t}\}_{i=1,t=1}^{N,T-1}$ be the control policies that generate feedback Nash equilibrium.
By applying the Cost Difference Lemma (Lemma \ref{lemma:costDifference}), we have
\begin{align*}
    &\text{Regret}_{T}((\mathbf{u}_{t})_{t=1}^{T-1})\\
    &= \frac{1}{N}\sum_{i=1}^{N}\sum_{t=1}^{T-1} Q_{i,T,t}^{\{\tilde{\pi}_{i,\tau}\}_{i=1,\tau=t}^{N,T-1}}(x_{t},u_{1,t},...,u_{N,t}) -  V_{i,T,t}^{\{\tilde{\pi}_{i,\tau}\}_{i=1,\tau=t}^{N,T-1}}(x_{t})\\
    &= \frac{1}{N}\sum_{i=1}^{N}\sum_{t=1}^{T-1} x_{t}^{\transpose}Q_{t}x_{t} + \mathbf{u}_{t}^{\transpose}R_{t}^{i}\mathbf{u}_{t} + (Ax_{t}+\mathbf{B}\mathbf{u}_{t})^{\transpose}P_{t+1}^{i}(Ax_{t}+\mathbf{B}\mathbf{u}_{t})\\
    &\qquad - x_{t}^{\transpose}Q_{t}x_{t} - \contTilde{u}_{t}^{\transpose}R_{t}^{i}\contTilde{u}_{t} - (Ax_{t}+\mathbf{B}\contTilde{u}_{t})^{\transpose}P_{t+1}^{i}(Ax_{t}+\mathbf{B}\contTilde{u}_{t})\\
    &= \frac{1}{N}\sum_{i=1}^{N}\sum_{t=1}^{T-1} \mathbf{u}_{t}^{\transpose}(R_{t}^{i}+\mathbf{B}^{\transpose}P_{t+1}^{i}\mathbf{B})\mathbf{u}_{t}-\contTilde{u}_{t}^{\transpose}(R_{t}^{i}+\mathbf{B}^{\transpose}P_{t+1}^{i}\mathbf{B})\contTilde{u}_{t} \\
    &\qquad+ 2x_{t}^{\transpose}A^{\transpose}P_{t+1}^{i}B(\mathbf{u}_{t}-\contTilde{u}_{t})\\
    &= \frac{1}{N}\sum_{i=1}^{N}\sum_{t=1}^{T-1} (\mathbf{u}_{t}-\contTilde{u}_{t})^{\transpose}(R_{t}^{i}+\mathbf{B}^{\transpose}P_{t+1}^{i}\mathbf{B})(\mathbf{u}_{t}-\contTilde{u}_{t})\\
    &\qquad + 2(\mathbf{u}_{t}-\contTilde{u}_{t})^{\transpose}\bigg((R_{t}^{i}+\mathbf{B}^{\transpose}P_{t+1}^{i}\mathbf{B})\contTilde{u}_{t}+\mathbf{B}^{\transpose}P_{t+1}^{i}Ax_{t}\bigg)\\
    &= \frac{1}{N}\sum_{i=1}^{N}\sum_{t=1}^{T-1} (\mathbf{u}_{t}-\contTilde{u}_{t})^{\transpose}(R_{t}^{i}+\mathbf{B}^{\transpose}P_{t+1}^{i}\mathbf{B})(\mathbf{u}_{t}-\contTilde{u}_{t})\\
    &\qquad + 2(\mathbf{u}_{t}-\contTilde{u}_{t})^{\transpose}\bigg((R_{t}^{i}+\mathbf{B}^{\transpose}P_{t+1}^{i}\mathbf{B})\bar{K}_{t}^{*}+\mathbf{B}^{\transpose}P_{t+1}^{i}A\bigg)x_{t}.
\end{align*}
Since
\begin{align*}
    \|\mathbf{u}_{t} - \contTilde{u}_{t}\|
    &= \|\bar{K}x_{t} + (\bar{K}_{t\mid t}-\bar{K})x_{t\mid t} - \bar{K}_{t}^{*}x_{t}\|\\
    &= \|(\bar{K}_{t}^{*}-\bar{K})(x_{t\mid t}-x_{t})  + (\bar{K}_{t|t}-\bar{K}_{t}^{*})x_{t|t}\|\\
    &\leq \|\bar{K}_{t}^{*}-\bar{K}\|\|x_{t\mid t}-x_{t}\|  + \|\bar{K}_{t|t}-\bar{K}_{t}^{*}\| \|x_{t|t}\|,
\end{align*}
and from the fact that for any $a_{1}, a_{2} \in \mathbb{R}$, $(a_{1}+a_{2})^2 \leq 2(a_{1}^{2}+a_{2}^{2})$,
 we have
\begin{align*}
    \|\mathbf{u}_{t} - \contTilde{u}_{t}\|^{2}
    &= \|\bar{K}x_{t} + (\bar{K}_{t\mid t}-\bar{K})x_{t\mid t} - \bar{K}_{t}^{*}x_{t}\|^{2}\\
    &\leq 2(\|\bar{K}_{t}^{*}-\bar{K}\|^{2}\|x_{t\mid t}-x_{t}\|^{2}  + \|\bar{K}_{t|t}-\bar{K}_{t}^{*}\|^{2} \|x_{t|t}\|^{2}),
\end{align*}

By Proposition~\ref{corollary:Delta}, there exist $\Delta_{1}>0,\Delta_{2}>0$, such that
\begin{align}
    &\text{Regret}((\mathbf{u}_{t})_{t=1}^{T-1})\notag \\
    &= \frac{1}{N}\sum_{i=1}^{N}\sum_{t=1}^{T-1} (\mathbf{u}_{t}-\contTilde{u}_{t})^{\transpose}(R_{t}^{i}+\mathbf{B}^{\transpose}P_{t+1}^{i}\mathbf{B})(\mathbf{u}_{t}-\contTilde{u}_{t})\notag \\
    &\qquad + 2(\mathbf{u}_{t}-\contTilde{u}_{t})^{\transpose}\bigg((R_{t}^{i}+\mathbf{B}^{\transpose}P_{t+1}^{i}\mathbf{B})\bar{K}_{t}^{*}+\mathbf{B}^{\transpose}P_{t+1}^{i}A\bigg)x_{t}\notag \\
    &\leq \sum_{t=1}^{T-1} (\mathbf{u}_{t}-\contTilde{u}_{t})^{\transpose}\bigg[\sum_{i=1}^{N}\frac{1}{N}(R_{t}^{i}+\mathbf{B}^{\transpose}P_{t+1}^{i}\mathbf{B})\bigg](\mathbf{u}_{t}-\contTilde{u}_{t})\notag \\
    &\qquad + (\mathbf{u}_{t}-\contTilde{u}_{t})^{\transpose}\sum_{i=1}^{N}\bigg( (R_{t}^{i}+\mathbf{B}^{\transpose}P_{t+1}^{i}\mathbf{B})\bar{K}_{t}^{*}+\mathbf{B}^{\transpose}P_{t+1}^{i}A\bigg)x_{t} \notag\\
    &\leq \Delta_{1} \sum_{t=1}^{T-1} \|\mathbf{u}_{t}-\contTilde{u}_{t}\|^2 + \Delta_{2}\sum_{t=1}^{T-1} \|\mathbf{u}_{t}-\contTilde{u}_{t}\|(\|x_{t}-x_{t|t}\| + \|x_{t|t}\|)\notag \\
    &\leq 2\Delta_{1} \sum_{t=1}^{T-1} \bigg(\|\bar{K}_{t}^{*}-\bar{K}\|^{N}\|x_{t\mid t}-x_{t}\|^{N}  + \|\bar{K}_{t|t}-\bar{K}_{t}^{*}\|^{N} \|x_{t|t}\|^{N} \bigg) \notag\\
    &\qquad + \Delta_{2}\sum_{t=1}^{T-1}\bigg( \|\bar{K}_{t}^{*}-\bar{K}\|\|x_{t\mid t}-x_{t}\|  + \|\bar{K}_{t|t}-\bar{K}_{t}^{*}\| \|x_{t|t}\|\bigg)\notag \\
    &\qquad\qquad\bigg(\|x_{t}-x_{t|t}\| + \|x_{t|t}\|\bigg), \label{eq:RegredUnsimplified}
\end{align}
where $\Delta_{1} = \max_{t} \frac{1}{N}\sum_{i=1}^{N}(R_{t}^{i}+\mathbf{B}^{\transpose}P_{t+1}^{i}\mathbf{B})$,
    $\Delta_{2} = \max_{t} \sum_{i=1}^{N}\bigg( (R_{t}^{i}+\mathbf{B}^{\transpose}P_{t+1}^{i}\mathbf{B})\bar{K}_{t}^{*}+\mathbf{B}^{\transpose}P_{t+1}^{i}A\bigg)$.
    Applying Lemma \ref{lemma:distanceXt} and using the same $q$ as in this lemma, we have
\begin{align*}
    \|x_{t}-x_{t|t}\|&\leq C_{fb}^{2}\|\bar{x}_{1}\|q^{t}[\frac{C_{K}\gamma^{W}}{\gamma-1}\bigg(\frac{1-(\frac{\eta\gamma}{q})^{t}}{1-\frac{\eta\gamma}{q}} - \frac{1-(\frac{\eta}{q})^{t}}{1-\frac{\eta}{q}} \bigg)\\
    &\qquad+\varepsilon_{K}\bigg(\frac{(t-1)(\frac{\eta}{q})^{t+1}-t(\frac{\eta}{q})^{t}+\frac{\eta}{q}}{(1-\frac{\eta}{q})^{2}}\bigg)]\\
    &\leq C_{x}\|\bar{x}_{1}\|q^{t}.
\end{align*}
To simplify the presentation of the main result, define
\begin{align*}
    &C_{*} := \max_{t} \|\bar{K}_{t}^{*}-\bar{K}\|,\\
    &D_{K}(\gamma^{W},\varepsilon_{K}) := \frac{C_{K}\gamma^{W}q\eta(\gamma-1)}{(q-\eta\gamma)(q-\eta)} + \frac{\varepsilon_{K}q\eta}{(q-\eta)^{2}},\\
    &C_{x} := C_{fb}^{2}D_{K}(\gamma^{W},\varepsilon_{K}),\\
    &\Delta_{a}(\gamma^{W},\varepsilon_{K}) := 2(\Delta_{1}+\Delta_{2})C_{*}^{2}D_{K}(\gamma^{W},\varepsilon_{K})C_{x}^{2},\\
    &\Delta_{b}(\gamma^{W},\varepsilon_{K}) := 4\Delta_{1}C_{fb}^{2}(C_{K}^{'2}\gamma^{2W}+\frac{\varepsilon_{K}^{2}}{\|\contB\|^{2}} )+2\Delta_{2}(C_{K}^{'}\gamma^{W}+\frac{\varepsilon_{K}}{\|\contB\|}),\\
    &\Delta_{c}(\gamma^{W},\varepsilon_{K}) := 2C_{x}C_{fb}\Delta_{2}(C_{K}^{'}\gamma^{W}+\frac{\varepsilon_{K}}{\|\contB\|}+C_{*}D_{K}(\gamma^{W},\varepsilon_{K})),
\end{align*}
where constants $C^{'}_{K}, \varepsilon_{K}$, and $C_{fb}$ are from Lemmas \ref{lemma:boundedPK} to \ref{lemma:distanceXt}.
\begin{align*}
        &\text{Regret}_{T}((\mathbf{u}_{t})_{t=1}^{T-1})< \|\bar{x}_{1}\|^{2}\bigg[\Delta_{a}(\gamma^{W},\varepsilon_{K^{'}})\frac{1-q^{2T}}{1-q^{2}}\\
        &+  \Delta_{b}(\gamma^{W},\varepsilon_{K^{'}})\frac{1-\eta^{2T}}{1-\eta^{2}}+ \Delta_{c}(\gamma^{W},\varepsilon_{K^{'}})\frac{1-(q\eta)^{T}}{1-q\eta}\bigg],
    \end{align*}
    where $\bar{P}_{max}$ satisfies
    \begin{align*}
        \bar{P}_{max} &= \bar{Q}_{max} + A^{\transpose}\bar{P}_{max}A \\
        &- A^{\transpose}\bar{P}_{max}\contB(\bar{R}_{max}+\contB^{\transpose}\bar{P}_{max}\contB)^{-1}\contB^{\transpose}\bar{P}_{max}A,
    \end{align*}
    and
    \begin{align*}
        &\alpha_{\tau,t} := \lambda_{max}(A^{\transpose}(\bar{P}_{\tau+1|t}^{-1}+B\bar{R}_{\tau|t}^{-1}B^{\transpose})^{-1}A),\\
        &\beta_{\tau,t} := \lambda_{min}(\bar{Q}_{\tau|t}),\\ 
        &\gamma := \max_{1\leq \tau,t \leq T} \frac{\alpha_{\tau,t}}{\alpha_{\tau,t}+\beta_{\tau,t}},\\
        &q = \rho(A+B\bar{K}) + \varepsilon(0\leq \varepsilon < 1-\rho(A+B\bar{K})),\\
        &\eta = \sqrt{1-\frac{\lambda_{min}(\bar{Q}_{min})}{\lambda_{max}(\bar{P}_{max})}},\\
        &\Delta_{1} := \max_{t} \frac{1}{N}\sum_{i=1}^{N}(R_{t}^{i}+\mathbf{B}^{\transpose}P_{t+1}^{i}\mathbf{B}),\\
        &\Delta_{2} := \max_{t} \sum_{i=1}^{N}\bigg( (R_{t}^{i}+\mathbf{B}^{\transpose}P_{t+1}^{i}\mathbf{B})\bar{K}_{t}^{*}+\mathbf{B}^{\transpose}P_{t+1}^{i}A\bigg),\\
        &\varepsilon_{1} = \max\bigg(1+\frac{\lambda_{max}(Q_{\tau|t}-Q_{\tau|t_{0}})}{\lambda_{min}(\bar{P}_{\tau|t_{0}})},1+\frac{\lambda_{max}(Q_{\tau|t_{0}}-Q_{\tau|t})}{\lambda_{min}(\bar{P}_{\tau|t})}\bigg),\\
        &h := \log(\frac{\lambda_{max}(\bar{P}_{max})}{\lambda_{min}(\bar{Q}_{min})}),\\
        &\varepsilon_{K} =\|\contB\|\frac{\varepsilon_{1}(e^{h}-1)\lambda_{max}(\bar{P}_{max})}{h(1-\gamma)},\\
        &C_{K} = \left\|(\bar{R}_{min}+\contB^{\mathsf{T}}\bar{Q}_{min}\contB)^{-1}\right\|^{2}\left\|\bar{R}_{max}\contB^{\mathsf{T}}\right\|\frac{\lambda_{max}^{2}(\bar{P}_{max})}{\lambda_{min}(\bar{Q}_{min})},\\
        &D_{K} := \frac{C_{K}q\eta(\gamma-1)}{(q-\eta\gamma)(q-\eta)} + \frac{\varepsilon_{K}q\eta}{(q-\eta)^{2}},\\
        &C_{x} := C_{fb}^{2}D_{K},\\
        &\Delta_{a}(z,y) := 2(\Delta_{1}+\Delta_{2})D_{K}(z,y)C_{x}^{2},\\
        &\Delta_{b}(z,y) := 4\Delta_{1}C_{fb}^{2}(C_{K}^{2}z^{2}+y^{2})+2\Delta_{2}(C_{K}z+y),\\
        &\Delta_{c}(z,y) := 2C_{x}C_{fb}\Delta_{2}(C_{K}z+y+D_{K}),\\
    \end{align*}
To simplify \eqref{eq:RegredUnsimplified}, let
\begin{align*}
    \Gamma_1(t) &:= C_{*}^{2}D_{K}(\gamma^{W},\varepsilon_{K})C_{x}^{2}q^{2t} + 2(C_{K}^{'2}\gamma^{2W}+\varepsilon_{K}^{'2})C_{fb}^{2}\eta^{2t} \\
    \Gamma_2(t) &:= C_{*}D_{K}(\gamma^{W},\varepsilon_{K})C_{x}q^{t}+(C_{K}^{'}\gamma^{W}+\varepsilon_{K}^{'})C_{fb}\eta^{t},\\
    \Gamma_3(t) &:= C_{x}q^{t}+C_{fb}\eta^{t}
\end{align*}



By Lemmas \ref{lemma:boundedPK} and \ref{lemma:multGain} and use the same $\eta,\gamma$ as in the aforementioned Lemmas in the following, we have 

\begin{align*}
     \|\bar{K}_{t}^{*}-\bar{K}\|^{2}\|x_{t\mid t}-x_{t}\|^{2}  + \|\bar{K}_{t|t}-\bar{K}_{t}^{*}\|^{2} \|x_{t|t}\|^{2} & \leq \|\bar{x}_1\|^2\Gamma_1(t) \\
     \|\bar{K}_{t}^{*}-\bar{K}\|\|x_{t\mid t}-x_{t}\|  + \|\bar{K}_{t|t}-\bar{K}_{t}^{*}\| \|x_{t|t}\| & \leq \|\bar{x}_{1}\| \Gamma_2(t)\\
     \|x_{t}-x_{t|t}\| + \|x_{t|t}\| & \leq \|\bar{x}_{1}\|\Gamma_3(t).
\end{align*}
Moreover, using the geometric series sum, observe
\begin{align*}
   \sum_{t=1}^{T-1} \Gamma_1(t) \leq \overline{\Gamma}_1,\quad
   \sum_{t=1}^{T-1} \Gamma_2(t)\Gamma_3(t) \leq \overline{\Gamma}_2
 \end{align*}
where 
\begin{align*}
    \overline{\Gamma}_1 &= C_{*}^{2}D_{K}(\gamma^{W},\varepsilon_{K})C_{x}^{2}\frac{1-q^{2T}}{1-q^{2}} + 2C_{fb}^{2}(C_{K}^{'2}\gamma^{2W}+\varepsilon_{K}^{'2})\frac{1-\eta^{2T}}{1-\eta^{2}}\\
    \overline{\Gamma}_2 &=C_{*}D_{K}(\gamma^{W},\varepsilon_{K})C_{x}^{2}\frac{1-q^{2T}}{1-q^{2}}\\
    & \qquad +[D_{K}(\gamma^{W},\varepsilon_{K})C_{x}C_{fb}+C_{x}C_{fb}(C_{K}^{'}\gamma^{W}+\varepsilon_{K}^{'})]\frac{1-(q\eta)^{T}}{1-q\eta}\\
    &\qquad + C_{fb}^{2}(C_{K}^{'}\gamma^{W}+\varepsilon_{K}^{'})\frac{1-\eta^{2T}}{1-\eta^{2}} 
\end{align*}
Note that the right hand side of \eqref{eq:RegredUnsimplified} then can be bounded by $\overline{\Gamma}$ where
\begin{align*}
    \overline{\Gamma} &= \|\bar{x}_1\|^2 \left (2\Delta_1 \overline{\Gamma}_1 + \Delta_2 \overline{\Gamma}_2 \right )\\
    &= \|\bar{x}_{1}\|^{2}\left [\Delta_{a}(\gamma^{W},\varepsilon_{K}^{'})\frac{1-q^{2T}}{1-q^{2}} +  \Delta_{b}(\gamma^{W},\varepsilon_{K}^{'})\frac{1-\eta^{2T}}{1-\eta^{2}} \right .\\ 
    & \left . \qquad + \Delta_{c}(\gamma^{W},\varepsilon_{K}^{'})\frac{1-(q\eta)^{T}}{1-q\eta}\right ]
\end{align*}
upperbound the \emph{regret} by
\begin{align*}
   &2\Delta_{1}\|\bar{x}_{1}\|^{2}\sum_{t=1}^{T-1}\bigg(C_{*}^{2}D_{K}(\gamma^{W},\varepsilon_{K})C_{x}^{2}q^{2t} + 2(C_{K}^{'2}\gamma^{2W}+\varepsilon_{K}^{'2})C_{fb}^{2}\eta^{2t}\bigg) \\
   &\leq 2\Delta_{1}\|\bar{x}_{1}\|^{2}\bigg(C_{*}^{2}D_{K}(\gamma^{W},\varepsilon_{K})C_{x}^{2}\frac{1-q^{2T}}{1-q^{2}} \\
   &\qquad + 2C_{fb}^{2}(C_{K}^{'2}\gamma^{2W}+\varepsilon_{K}^{'2})\frac{1-\eta^{2T}}{1-\eta^{2}} \bigg),
\end{align*}
and
\begin{align*}
   &\sum_{t=1}^{T-1}\bigg( \|\bar{K}_{t}^{*}-\bar{K}\|\|x_{t\mid t}-x_{t}\|  + \|\bar{K}_{t|t}-\bar{K}_{t}^{*}\| \|x_{t|t}\|\bigg)\\
   &\qquad \bigg(\|x_{t}-x_{t|t}\| + \|x_{t|t}\|\bigg)\\
   &\leq \|\bar{x}_{1}\|^{2}\sum_{t=1}^{T-1}\bigg(C_{*}D_{K}(\gamma^{W},\varepsilon_{K})C_{x}q^{t}\\
   &+(C_{K}^{'}\gamma^{W}+\varepsilon_{K}^{'})C_{fb}\eta^{t}\bigg)(C_{x}q^{t}+C_{fb}\eta^{t})\\
   &\leq \|\bar{x}_{1}\|^{2}\bigg(C_{*}D_{K}(\gamma^{W},\varepsilon_{K})C_{x}^{2}\frac{1-q^{2T}}{1-q^{2}}\\
   &\qquad +[D_{K}(\gamma^{W},\varepsilon_{K})C_{x}C_{fb}+C_{x}C_{fb}(C_{K}^{'}\gamma^{W}+\varepsilon_{K}^{'})]\frac{1-(q\eta)^{T}}{1-q\eta}\\
   &\qquad + C_{fb}^{2}(C_{K}^{'}\gamma^{W}+\varepsilon_{K}^{'})\frac{1-\eta^{2T}}{1-\eta^{2}} \bigg).
\end{align*}
Thus,
\begin{align*}
   &\text{Regret}_{T}((\mathbf{u}_{t})_{t=1}^{T-1})\\
   &< \|\bar{x}_{1}\|^{2}\bigg[ 2\Delta_{1}\bigg(C_{*}^{2}D_{K}(\gamma^{W},\varepsilon_{K})C_{x}^{2}\frac{1-q^{2T}}{1-q^{2}} + 2C_{fb}^{2}(C_{K}^{2}\gamma^{2W}+\varepsilon_{K}^{'2})\frac{1-\eta^{2T}}{1-\eta^{2}} \bigg)\\
   &+2\Delta_{2}\bigg(C_{*}D_{K}(\gamma^{W},\varepsilon_{K})C_{x}^{2}\frac{1-q^{2T}}{1-q^{2}}\\
   &\qquad+[C_{*}D_{K}(\gamma^{W},\varepsilon_{K})C_{x}C_{fb}
    +C_{x}C_{fb}(C_{K}^{'}\gamma^{W}+\varepsilon_{K}^{'})]\frac{1-(q\eta)^{T}}{1-q\eta}\\
   &\qquad+ C_{fb}^{2}(C_{K}^{'}\gamma^{W}+\varepsilon_{K}^{'})\frac{1-\eta^{2T}}{1-\eta^{2}} \bigg)\bigg]\\
   &= \|\bar{x}_{1}\|^{2}\bigg[\Delta_{a}(\gamma^{W},\varepsilon_{K}^{'})\frac{1-q^{2T}}{1-q^{2}} +  \Delta_{b}(\gamma^{W},\varepsilon_{K}^{'})\frac{1-\eta^{2T}}{1-\eta^{2}}\\
   &\qquad + \Delta_{c}(\gamma^{W},\varepsilon_{K}^{'})\frac{1-(q\eta)^{T}}{1-q\eta}\bigg].
\end{align*}
By inspection, the regret upperbound, $\overline{\Gamma}$, can be expressed as $C_{1}\gamma^{W}+C_{2}\varepsilon_{K}$, where $C_{1}$ and $C_{2}$ are monotonically increasing w.r.t. $\lambda_{max}(R_{max})$ and $\lambda_{max}(Q_{max})$, and the inverse of $\rho(A+\contB\bar{K})$ and $\lambda_{max}(\bar{P}_{max})-\lambda_{min}(\bar{Q}_{min})$. 

% For $\varepsilon_{K}$, monotonically decreasing of $\lambda_{min}(\bar{Q}_{min})$ leads to monotonically increasing of $\varepsilon_{K}$. Since,
% \begin{align*}
%     \lambda_{min}(Q_{min}) = \min_{t}\lambda_{min}(Q_{t} + K^{\transpose}(R_{t}^{1}-\bar{R}_{t})K)
% \end{align*}





\end{document}
