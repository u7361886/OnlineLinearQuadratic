\documentclass{article}
\usepackage{times}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{appendix}
\usepackage{xr}
\externaldocument[aux]{Auxillary.tex}

% \newtheorem{lemma}{Lemma}
% \newtheorem{problem}{Problem}
% \newtheorem{theorem}{Theorem}
% \newtheorem{assumption}{Assumption}
% \newtheorem{remark}{Remark}


% \newcommand{\contTilde}[1]{\mathbf{\tilde{#1}}}
% \newcommand{\contBar}[1]{\bar{\mathbf{#1}}}
% \newcommand{\transpose}{\mathsf{T}}
% \newcommand{\infoat}[1]{\mathcal{H}_{#1}}
% \newcommand{\opcontrol}[2]{\pi^{*}(#1,\infoat{#2})}
% \newcommand{\lqr}[3]{{#1}^{\transpose}Q_{#3}{#1}+{#2}^{\transpose}R_{#3}{#2}}
% \newcommand{\quadx}[2]{{#1}^{\transpose}{#2}{#1}}
% \newcommand{\gameVars}[2]{\{x_{t}\}_{t=1}^{#1}, \{u_{i,t}\}_{i=1,t=1}^{#2,#1}}
% \newcommand{\gameVarAtTime}[2]{x_{t},\{{#1}_{i,t}\}_{i=1}^{#2}}
% \newcommand{\gameVarPlayer}[3]{x_{#3},{#1}_{#3}^{#2}, \mathbf{u}_{#3}^{-#2}}
% \newcommand{\myinner}[1]{\langle(#1)x,x\rangle}


\newcommand{\usequence}[2]{\{u_{i,t}\}_{i=1,t=1}^{#1,#2}}
\newcommand{\contTilde}[1]{\mathbf{\tilde{#1}}}
\newcommand{\transpose}{\mathsf{T}}
\newcommand{\myinner}[1]{\langle(#1)x,x\rangle}
\newcommand{\quadinner}[1]{x^{\transpose}(#1)x}
\DeclareMathOperator{\Log}{\mathrm{Log}}
\newcommand{\BK}[1]{\mathbf{B}\bar{K}_{#1}}
% \newcommand{\Log}[1]{\text{Log}}

\newtheorem{problem}{Problem}
\newtheorem{lemma}{Lemma}
\newtheorem{assumption}{Assumption}
\newtheorem{definition}{Definition}
\newtheorem{corollary}{Corollary}
\newtheorem{proposition}{Proposition}
\newtheorem{remark}{Remark}
\newtheorem{theorem}{Theorem}


\title{On the Regret Analysis of Online Feedback Potential Dynamic Game via Trajectory Prediction and Tracking}
\author{Yitian Chen}
% \date{June 2023}

\begin{document}

\maketitle

\section{INTRODUCTION}
For a positive integer $N$, consider the linear systems
\begin{equation}\label{eq:linsys}
    x_{t+1} = Ax_{t} + \mathbf{B}\mathbf{u}_{t},
\end{equation}
where $t,i$ are nonegative integers, $m$ and $n$ are positive integers, $A \in \mathbb{R}^{n\times n}$, $\mathbf{B} := [B^{1},\cdots, B^{N}]$, $B^{i} \in \mathbb{R}^{n\times m}$, $\mathbf{u}_{t} = [u_{1,t}^{\transpose},\cdots,u_{N,t}^{\transpose}]^{\transpose}$, $x_t\in\mathbb{R}^n$, and $x_{1} =\bar{x}_{1}$ for some $\bar{x}_1 \in \mathbb{R}^{n}$, and $u_{t} \in \mathbb{R}^{m}$. Suppose matrix $\mathbf{H}$ is expressed as a collection of block matrices, i.e.,
\begin{align*}
    \mathbf{H} = 
    \begin{bmatrix}
        H_{11} & H_{12} & \cdots & H_{1n}\\
        \vdots & \vdots & \vdots & \vdots\\
        H_{n1} & \cdots & \cdots & H_{nn}
    \end{bmatrix}.
\end{align*}
For each $i,j(1\leq i,j\leq n)$, we define the notation
\begin{equation}
    [\mathbf{H}]_{ij} := H_{ij}.
\end{equation}


Moreover, define the following notations
\begin{align}
    &\{u_{i,t}\}_{i=1,t=1}^{N,T-1} := \{u_{1,1},\cdots,u_{N,1},\cdots, u_{1,T-1},\cdots,u_{N,T-1}\},\\
    \begin{split}
         &\{u_{i,t}\}_{i=1,t=1}^{N,\tau-1} \frown \{v_{i,t}\}_{i=1,t=\tau}^{N,T-1}:=\{u_{1,1},\cdots,u_{1,\tau-1},v_{1,\tau},\cdots,\\
    &\qquad v_{1,T-1},\cdots,u_{N,1},\cdots,u_{N,\tau-1},v_{N,\tau},\cdots,v_{N,T-1} \},
    \end{split}
   \\ 
   & R_{t}^{i} := 
   \begin{bmatrix}
       [R_{t}^{i}]_{11} & \cdots & [R_{t}^{i}]_{1N}\\
       \vdots & \vdots & \vdots\\
       [R_{t}^{i}]_{N1} & \cdots & [R_{t}^{i}]_{NN}
   \end{bmatrix},\\
    \label{eq:history}
    &\mathcal{H}_{T} := \{ \bar{x}_{1},\{Q_{t}^{i}\}_{i=1,t=1}^{N,T},\{R_{t}^{i}\}_{i=1,t=1}^{N,T-1}\},\\
    &g_{i,t}(x_{t}, \mathbf{u}_{t}) := \frac{1}{2}(x_{t}^{\mathsf{T}}Q_{t}^{i}x_{t} + 
    \mathbf{u}_{t}^{\transpose}R_{t}^{i}\mathbf{u}_{t}),\\
    &g_{i,T}(x) := \frac{1}{2} x^{\mathsf{T}}Q_{T}^{i}x,
\end{align}
where for all $1 \leq t \leq T$ and $1\leq i,j\leq N$, $Q_{t}^{i}$ is symmetric, positive semi-definite, $[R_{t}^{i}]_{pq}(1\leq p,q \leq 2)$ is positive definite. We again define
\begin{equation}
    J_{i,T}(\{x_{t}\}_{t=1}^{T},\{u_{i,t}\}_{i=1,t=1}^{N,T-1}) := \sum_{t=1}^{T-1} g_{i,t}(x_{t}, \mathbf{u}_{t}) + g_{i,T}(x_{T}).
\end{equation}

Before we start the discussion of feedback Nash equilibrium, we use $\{u_{i,t}^{*}\}_{i=1,t=1}^{N,T-1}$ to denote the control sequence for feedback Nash equilibrium, and $\{u_{i,t}\}_{i=1,t=1}^{N,T-1}$ is sequence that consisted by arbitrary control vectors for each players. 

Furthermore, for $1 \leq \tau \leq T$, $\{x_{t}^{*\tau}\}_{t=1}^{T}$ is generated by the sequence of $\{u_{i,t}\}_{i=1,t=1}^{N,\tau-1} \frown \{u_{i,t}^{*}\}_{i=1,t=\tau}^{N,T}$, where $u_{i,t}$ can be an arbitrary vector from $\mathbb{R}^{m}$ for $1 \leq i \leq N$ and $1 \leq t \leq T$. Moreover, for $1 \leq \tau \leq T$ and $1 \leq i \leq N$, $\{x_{t}^{(i,K)}\}_{t=1}^{T}$ is generated by $\{u_{i,t}\}_{i=1,t=1}^{N,\tau-1} \frown \{u_{1,\tau}^{*},\dots, u_{i,\tau},\dots,u_{N,\tau}^{*}\} \frown \{u_{i,t}^{*}\}_{i=1,t=\tau+2}^{N,T}$. 

The sequence $\{ u_{i,t}^{*}\}_{i=1,t=1}^{N,T}$ satisfy that, for any fix $i$ that $1 \leq i \leq N$, such 
sequence satisfy that 
\begin{equation}\label{eq:nashIneq}
    \begin{split}
        \text{Level T}
        &\begin{cases}
            &J_{1,T}(\{x_{t}^{*T}\}_{t=1}^{T}, \{u_{i,t}\}_{i=1,t=1}^{N,T-2} \frown \{u_{1,T}^{*},u_{2,T}^{*},\dots,u_{N,T}^{*}\}) \\ & \leq J_{1,T}(\{x_{t}^{(1,T)}\}_{t=1}^{T}, \{u_{i,t}\}_{i=1,t=1}^{N,T-2} \frown \{u_{1,T},u_{2,T}^{*},\dots,u_{N,T}^{*}\}),\\ \\
            &J_{2,T}(\{x_{t}^{*T}\}_{t=1}^{T}, \{u_{i,t}\}_{i=1,t=1}^{N,T-2} \frown \{u_{1,T}^{*},u_{2,T}^{*},\dots,u_{N,T}^{*}\}) \\ & \leq J_{2,T}(\{x_{t}^{(2,T)}\}_{t=1}^{T}, \{u_{i,t}\}_{i=1,t=1}^{N,T-2} \frown \{u_{1,T}^{*},u_{2,T},\dots,u_{N,T}^{*}\}),\\
            & \qquad \qquad \vdots \\
            &J_{N,T}(\{x_{t}^{*T}\}_{t=1}^{T}, \{u_{i,t}\}_{i=1,t=1}^{N,T-2} \frown \{u_{1,T}^{*},u_{2,T}^{*},\dots,u_{N,T}^{*}\}) \\ & \leq J_{N,T}(\{x_{t}^{(N,T)}\}_{t=1}^{T}, \{u_{i,t}\}_{i=1,t=1}^{N,T-2} \frown \{u_{1,T}^{*},u_{2,T}^{*},\dots,u_{N,T}\}).
        \end{cases}
    \\ &\qquad \qquad \qquad \vdots \\
    \text{Level 1}
        &\begin{cases}
            &J_{1,T}(\{x_{t}^{*1}\}_{t=1}^{T}, \{u_{1,1}^{*},u_{2,1}^{*},\dots,u_{N,1}^{*}\} \frown \{u_{i,t}^{*}\}_{i=1,t=2}^{N,T-1}) \\ & \leq J_{1,T}(\{x_{t}^{(1,1)}\}_{t=1}^{T}, \{u_{1,1},u_{2,1}^{*},\dots,u_{N,1}^{*}\} \frown \{u_{i,t}^{*}\}_{i=1,t=2}^{N,T-1}),\\ \\
            &J_{2,T}(\{x_{t}^{*1}\}_{t=1}^{T}, \{u_{1,1}^{*},u_{2,1}^{*},\dots,u_{N,1}^{*}\} \frown \{u_{i,t}^{*}\}_{i=1,t=2}^{N,T-1}) \\ & \leq J_{2,T}(\{x_{t}^{(2,1)}\}_{t=1}^{T}, \{u_{1,1}^{*},u_{2,1},\dots,u_{N,1}^{*}\} \frown \{u_{i,t}^{*}\}_{i=1,t=2}^{N,T-1}),\\
            & \qquad \qquad \vdots \\
            &J_{N,T}(\{x_{t}^{*1}\}_{t=1}^{T}, \{u_{1,1}^{*},u_{2,1}^{*},\dots,u_{N,1}^{*}\} \frown \{u_{i,t}^{*}\}_{i=1,t=2}^{N,T-1}) \\ & \leq J_{N,T}(\{x_{t}^{(N,1)}\}_{t=1}^{T}, \{u_{1,1}^{*},u_{2,1}^{*},\dots,u_{N,1}\} \frown \{u_{i,t}^{*}\}_{i=1,t=2}^{N,T-1}).
        \end{cases}
    \end{split}
\end{equation}
For convenient use later, we define the notion of $\text{DFLGame}$ as
\begin{equation}\label{eq:regret}
 (\{x_{t}^{*1}\}_{t=1}^{T}, \{u_{i,t}^{*}\}_{i=1,t=1}^{N,T}) := \text{DFLGame}(\mathcal{H}_{T},T).
\end{equation}
For any decisions $\usequence{N}{T-1}$ and the associated state sequence $\{x_{t}\}_{t=1}^{T}$, the dynamic social regret is defined as
\begin{equation}
    \begin{split}
        &\text{Regret}_{T}(\{\mathbf{u}_{t}\}_{t=1}^{T-1}) := \\
        &\sum_{i=1}^{N} J_{i,T}(\{x_{t}\}_{t=1}^{T},\{u_{i,t}\}_{i=1,t=1}^{N,T-1}) - J_{i,T}(\{x_{t}^{*}\}_{t=1}^{T},\{u_{i,t}^{*}\}_{i=1,t=1}^{N,T-1}).
    \end{split}
\end{equation}


The key contributions of this paper are
\begin{itemize}
    \item The proposal of a method to solve a online LQ potential game;
    \item Development of the social-regret upperbound;
\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{PROBLEM FORMULATION}
\begin{assumption}\label{assumption:bounds}
    For any given $p,q(p={1,2}\text{ and }q={1,2})$, there exists positive definite matrices $Q_{min}, Q_{max}, R_{min}, R_{max}$ that
    \begin{equation}
        Q_{min} \preceq Q_{t} \preceq Q_{max},
    \end{equation}
    for $1\leq t \leq T$, and
    \begin{equation}
        R_{min} \preceq [R_{t}^{p}]_{p,q} \preceq R_{max},
    \end{equation}
    for $1 \leq t \leq T-1$.
\end{assumption}

\begin{assumption}\label{assumption:controllable}
    Matrices $A,B^{1},B^{2}$ are controllable.
\end{assumption}
In this paper, we consider the following problem.
\begin{problem}[Online Dynamic LQ Game]
     Consider the controllable system \eqref{eq:linsys}. Let the cost matrices in \eqref{eq:regret} satisfy Assumption \ref{assumption:controllable} for any given $T \geq 1$ and $W < T-1$. At time $0 \leq t \leq T-W-1$, the available information to the decision maker is given by $\mathcal{H}_{t}$ as defined in \eqref{eq:history} and the current state $x_{t}$. It is desired to design a control policy $\pi(\cdot, \cdot)$ of the form \eqref{eq:policyForm} that yields a regret, as defined by \eqref{eq:regret}, that is independent of the bounds given in Assumption \ref{assumption:bounds}.
\end{problem}

\section{APPROACH AND REGRET ANALYSIS}
In the following sections, we consider the special case of $N = 2$. 
\paragraph{Prediction. } 
Define
\begin{equation}
    [\bar{R}_{t}]_{pq} := [R_{t}^{p}]_{pq},
\end{equation}
for $1 \leq p,q \leq 2$. Given a preview window length $W$, define
\begin{equation}
\begin{split}
    \Pi_{\tau|t}(x_{\tau},\mathbf{u}_{\tau}) := 
    \begin{cases}
        \frac{1}{2} (x_{\tau}^{\transpose}Q_{\tau}x_{\tau} +  \mathbf{u}_{\tau}^{\transpose}\bar{R}_{\tau}\mathbf{u}_{\tau}) \text{\quad if $\tau \leq t+W$}\\
        \frac{1}{2} (x_{\tau}^{\transpose}Q_{t}x_{\tau} + \mathbf{u}_{\tau}^{\transpose}\bar{R}_{t+W}\mathbf{u}_{\tau}) \text{\quad if $t+W \leq \tau \leq T-1$}.
    \end{cases}
\end{split}
\end{equation}

At each time $t$, we plan an optimal trajectory starting from the initial state $\bar{x}_{1}$ using the known cost matrices up to time $t+W$ and setting all the future matrices to be equal to their known values for time $t+W$.

Specifically, at time $t$ where $0\leq t < T-W$, define $\Psi_{t}(\cdot,\cdot)$ as
\begin{align}
\Psi_{t}(\{\xi_{\tau}\}_{\tau=1}^{T},\{\boldsymbol{\upsilon}_{\tau}\}_{\tau=1}^{T-1}) &:= \sum_{\tau=1}^{T-1} \Pi_{\tau|t}(\xi_{\tau},\boldsymbol{\upsilon}_{\tau}) + \frac{1}{2} \xi_{T}^{\transpose}Q_{t+W}\xi_{T},
\end{align}
and 
\begin{equation}
    \Psi_{t}(\{\xi_{\tau}\}_{\tau=1}^{T},\{\boldsymbol{\upsilon}_{\tau}\}_{\tau=1}^{T-1}) = J_{t}(\{\xi_{\tau}\}_{\tau=1}^{T},\{\boldsymbol{\upsilon}_{\tau}\}_{\tau=1}^{T-1}),
\end{equation}
for $T-W \leq t \leq T-1$.
Then, we find the predicted optimal control sequence for all $0\leq \tau\leq T-1$ by solving
\begin{equation}
\begin{split}
    (\{x_{\tau|t}\}_{\tau=1}^{T}, \{\mathbf{u}_{\tau|t}\}_{\tau=1}^{T-1}) \in &\arg\min_{\{\xi_{\tau}\}_{\tau=1}^{T},\{\upsilon_{\tau}\}_{\tau=1}^{T-1}} \Psi_{t}(\{\xi_{\tau}\}_{\tau=1}^{T},\{\upsilon_{\tau}\}_{\tau=1}^{T-1}),\\
    &\text{subject to}\quad \xi_{\tau+1} = A\xi_{\tau} + \mathbf{B}\mathbf{\upsilon_{\tau}}, \xi_{1} = \bar{\xi}_{1}.
\end{split}
\end{equation}

\paragraph{Prediction Tracking. } We propose the following feedback control policy
\begin{equation}
    \pi(x_{t},\mathbf{H}_{t}) := \mathbf{K}(x_{t}-x_{t|t}) + \mathbf{u}_{t|t},
\end{equation}
where $\mathbf{K}\in \mathbb{R}^{m\times n}$ is a control matrix such that $\rho(A+\mathbf{B}\mathbf{K}) < 1$, and $\rho(\cdot)$ denotes the matrix spectral radius.


\subsection{Regret Analysis}

\begin{definition}
    The dynamic game is referred to as a feedback potential difference game(FPDG) if there exist an optimal control problem (OCP) such that the solution of the OCP, in feedback form, provides a feedback Nash equlibrium for the linear quadratic dynamic game. 
\end{definition}

\begin{lemma}
    If the cost matrices $Q_{t}$, $R_{t}^{i}$ satisfy the following,
    \begin{enumerate}
        \item for time instant $t$ from $T-1$ to 1, $R_{t}^{1},R_{t}^{2},Q_{t}$ satisfy
        \begin{equation}\label{eq:costFPDG1}
            [R_{t}^{1}]_{12} + B^{1\transpose}P_{t+1}^{1}B^{2} = ([R_{t}^{2}]_{21} + B^{2\transpose}P_{t+1}^{2}B^{1})^{\transpose}.
        \end{equation}
        Define
        \begin{equation}\label{eq:Theta}
        [\Theta_{t}]_{ij} := [R_{t}]^{i}_{ij} + B^{i\transpose}P_{t+1}^{i}B^{j},
        \end{equation}
        we require
        \begin{equation}
            \Theta_{t} \succ 0,
        \end{equation}
        \begin{equation*}
            \mathbf{B}^{\transpose}(P_{t}^{1}-P_{t}^{2})A=0.
        \end{equation*}
        \item at time instant 1: $(R_{1}^{1},R_{1}^{2})$ satisfy
        \begin{equation}
            [R_{1}^{1}]_{12} + B^{1\transpose}P_{1}^{1}B^{2} = ([R_{1}^{2}]_{21} + B^{2\transpose}P_{1}^{2}B^{1})^{\transpose},
        \end{equation}
        \begin{equation}\label{eq:costFPDG2}
            \Theta_{1} \succ 0.
        \end{equation}
    \end{enumerate}
    Then, the dynamic game is a feedback potential difference game(FPDG).
\end{lemma}
The above lemma is a special case of \cite{prasad_structure_2023}[Theorem 6] when $Q_{t}^{1}=Q_{t}^{2}$ for $t(1\leq t \leq T)$.

\begin{lemma}
    \cite{prasad_structure_2023}[Theorem 5]
    Define $\Omega := \{\bar{R}_{t}\in \mathbb{S}^{m\times m}\text{ for $1\leq t \leq T-1$ },\bar{Q}_{t}\in\mathbb{S}^{n\times n}\text{ for $1\leq t \leq T$ } \}$, where matrices $\bar{Q}_{t}$ and $\bar{R}_{t}$ satisfy the following conditions,
    \begin{enumerate}
        \item at time instant $T$, set $\bar{Q}_{T}$ such that
        \begin{equation}
            \mathbf{B}^{\transpose}\bar{Q}_{T}A = \mathbf{B}^{\transpose}Q_{T}A,
        \end{equation}
        Moreover, let $\bar{P}_{T}$ satisfy
        \begin{equation}
            \mathbf{B}^{\transpose}\bar{P}_{T}A = \mathbf{B}^{\transpose}Q_{T}A.
        \end{equation}
        \item at time instant $t$: from $t=T-1$ to $t=2$, set $\bar{R}_{t}$ as
        \begin{equation}\label{eq:matrixR}
            \bar{R}_{t} = \Theta_{t} - \mathbf{B}^{\transpose}\bar{P}_{t+1}\mathbf{B},
        \end{equation}
        and $\bar{Q}_{t}$ such that
        \begin{equation}
            \bar{Q}_{t} = Q_{t} + K_{t}^{\transpose}(R_{t}^{1}-\bar{R}_{t})K_{t}.
        \end{equation}
        \item at time instant $1$, set $\bar{R}_{1}$ as 
        \begin{equation}
            \bar{R}_{1} = \Theta_{1}-\mathbf{B}^{\transpose}\bar{P}_{2}\mathbf{B}.
        \end{equation}
    \end{enumerate}
    Then, every member in $\Omega$ is an associated ... for the ... Further, $\Omega$ is non-empty.
\end{lemma}

\begin{corollary}
    There exists matrices $\bar{R}_{min},\bar{R}_{max} \in \mathbf{S}_{++}^{m}$, that the cost matrix defined in \eqref{eq:matrixR} satisfy the following
    \begin{equation}
        0 \prec \bar{R}_{min} \preceq \bar{R}_{t} \preceq \bar{R}_{max},
    \end{equation}
    for $1\leq t \leq T-1$.
\end{corollary}
\begin{proof}
    By definition of $\bar{R}_{t}$, we have
    \begin{align*}
        \bar{R}_{t} &= 
        \begin{bmatrix}
            [R_{t}^{1}]_{11} & [R_{t}^{1}]_{12}\\
            [R_{t}^{2}]_{21} & [R_{t}^{2}]_{22}
        \end{bmatrix}
        + 
        \begin{bmatrix}
            B^{1\transpose}P_{t+1}^{1}\\
            B^{2\transpose}P_{t+1}^{2}
        \end{bmatrix}\mathbf{B}
        - \mathbf{B}^{\transpose}\bar{P}_{t+1}\mathbf{B}\\
        &= \begin{bmatrix}
            [R_{t}^{1}]_{11} & [R_{t}^{1}]_{12}\\
            [R_{t}^{2}]_{21} & [R_{t}^{2}]_{22}
        \end{bmatrix}
        + 
        (\begin{bmatrix}
            B^{1\transpose}P_{t+1}^{1}\\
            B^{2\transpose}P_{t+1}^{2}
        \end{bmatrix}-
        \begin{bmatrix}
            B^{1\transpose}\bar{P}_{t+1}\\
            B^{2\transpose}\bar{P}_{t+1}
        \end{bmatrix}
        )\mathbf{B}
    \end{align*}
    Due to Assumption \ref{assumption:controllable}, we have $A$ is full-rank. Therefore, for $1\leq p \leq 2$,
    \begin{align*}
        B^{p\transpose}P_{t+1}^{p} = B^{p\transpose}\bar{P}_{t+1}.
    \end{align*}
    Thus,
    \begin{align*}
        \bar{R}_{t} &= 
        \begin{bmatrix}
            [R_{t}^{1}]_{11} & [R_{t}^{1}]_{12}\\
            [R_{t}^{2}]_{21} & [R_{t}^{2}]_{22}
        \end{bmatrix}.
    \end{align*}
    Suppose $x\in \mathbb{R}^{2m}$ is non-zero. Let $x = [x_{1:m} | x_{m+1:2m}]$, we have
    \begin{align*}
        &x^{\transpose}\begin{bmatrix}
            [R_{t}^{1}]_{11} & [R_{t}^{1}]_{12}\\
            [R_{t}^{2}]_{21} & [R_{t}^{2}]_{22}
        \end{bmatrix}x \\
        &= x_{1:m}^{\transpose}[R_{t}^{1}]_{11}x_{1:m} + x_{m+1:2m}^{\transpose}[R_{t}^{2}]_{22}x_{m+1:2m} + x_{1:m}^{\transpose}[R_{t}^{1}]_{12}x_{m+1:2m} + x_{m+1:2m}^{\transpose}[R_{t}^{2}]_{21}x_{1:m}
    \end{align*}
    By using the properties of eigenvalues, we have
    \begin{align*}
        \lambda_{min}([R_{t}^{1}]_{11}) + \lambda_{min}([R_{t}^{2}]_{22}) \leq x_{1:m}^{\transpose}[R_{t}^{1}]_{11}x_{1:m} + x_{m+1:2m}^{\transpose}[R_{t}^{2}]_{22}x_{m+1:2m} \leq \lambda_{max}([R_{t}^{1}]_{11}) + \lambda_{max}([R_{t}^{2}]_{22}).
    \end{align*}
    Moreover, define $y = U_{[R_{t}^{1}]_{12}}x_{1:m}$ and $z = V_{[R_{t}^{1}]_{12}}^{*}x_{m+1:2m}$,
    \begin{align*}
        x_{1:m}^{\transpose}[R_{t}^{1}]_{12}x_{m+1:2m} &= \sum_{i=1}^{m} \lambda_{i}([R_{t}^{1}]_{12}x_{m+1:2m}) y_{i}z_{i} \\
        &\geq 0\\
        &\leq \lambda_{max}([R_{t}^{1}]_{12}).
    \end{align*}
    Similar procedures can be applied to matrix $[R_{t}^{2}]_{21}$. Therefore, 
    \begin{align*}
        x^{\transpose}\begin{bmatrix}
            [R_{t}^{1}]_{11} & [R_{t}^{1}]_{12}\\
            [R_{t}^{2}]_{21} & [R_{t}^{2}]_{22}
        \end{bmatrix}x
    \end{align*}
    has finite eigenvalues. We can thus construct such $\bar{R}_{min}$ and $\bar{R}_{max}$ that
    \begin{align*}
        0 \prec \bar{R}_{min} \preceq \bar{R}_{t} \preceq \bar{R}_{max},
    \end{align*}
    by eigen-decomposition of $\bar{R}_{t}$.
\end{proof}

\begin{remark}
    Based on the proof above, for any given $\tau,t(1\leq \tau \leq t \leq T-1)$, we have
    \begin{equation*}
        \bar{R}_{\tau|t} = \bar{R}_{\tau}.
    \end{equation*}
\end{remark}

\begin{lemma}\label{lemma:matrixK}
    Suppose $m \leq n$ and $R\in \mathbb{S}^{m}_{++}$ is a positive definite matrix. 
    If $P\in \mathbb{S}^{n}_{++}$, then for any given $B$ that has appropriate size and finite singular values, the matrix $(R+B^{\transpose}PB)^{-1}B^{\transpose}P$ has bounded singular values.
\end{lemma}
\begin{proof}
    Define an $n\times n$ matrix
    \begin{equation}
        \underbar{B} := 
        \begin{bmatrix}
            B & 0_{n\times n-m}
        \end{bmatrix}.
    \end{equation}
    
    Let $K := (R+B^{\transpose}PB)^{-1}B^{\transpose}P$. By using \cite[Theorem 4.5.9]{horn_matrix_2013} (see also the discussion on \cite[p.~284]{horn_matrix_2013}), for any $k(1\leq k\leq n,\text{where $dim(P)=n$})$, we have that
    \begin{align*}
        \lambda_{k}(B^{\transpose}K^{\transpose}KB) &= \lambda_{k}(\underbar{B}^{\transpose}K^{\transpose}K\underbar{B})\\
        &= \theta_{k}\lambda_{k}{K^{\transpose}K},
    \end{align*}
    where $0\leq \theta_{k} \leq \sigma_{max}(\underbar{B})=\sigma_{max}(B)$.
    Due to
    \begin{align*}
        \sigma_{k}(KB) &= \sigma_{k}((R+B^{\transpose}PB)^{-1}B^{\transpose}PB)\\
        &= \sigma_{k}\bigg((I - (R+B^{\transpose}PB)^{-1}R) \bigg),
    \end{align*}
    and
    \begin{align*}
       0 < \sigma_{k}\bigg((I - (R+B^{\transpose}PB)^{-1}R) \bigg) < 1,
    \end{align*}
    when $P \succ 0$, we can conclude that
    \begin{align}
        0 < \sigma_{k}(K) < \theta_{k}
    \end{align}
    for $1\leq k \leq n$.
\end{proof}

% \begin{proof}
%     Suppose the singular value decomposition of $B$ is given by
%     \begin{equation}
%         B = U_{B}\Lambda_{B}V_{B}^{\transpose}.
%     \end{equation}
%     Let $K := (R+B^{\transpose}PB)^{-1}B^{\transpose}P$. By using \cite{}[Theorem 4.5.9], for any $k(1\leq k\leq n,\text{where $dim(U_{B})=n$})$, we have that
%     \begin{align*}
%         \lambda_{k}(U_{B}^{\transpose}K^{\transpose}KU_{B}) = \lambda_{k}(K^{\transpose}K).
%     \end{align*}
%     Let
%     \begin{align*}
%         \tilde{\Lambda}_{B} := 
%         \begin{bmatrix}
%             \Lambda_{B} & 0\\
%             0 & 0
%         \end{bmatrix}.
%     \end{align*}
%     By using the extension of \cite{}[Theorem 4.5.9], we have that
%     \begin{align*}
%         \lambda_{k}(\Lambda_{B}^{\transpose}U_{B}^{\transpose}K^{\transpose}KU_{B}\Lambda_{B}) &= \lambda_{k}(\tilde{\Lambda}_{B}^{\transpose}U_{B}^{\transpose}K^{\transpose}KU_{B}\tilde{\Lambda}_{B})\\
%         &= \theta_{k}\lambda_{k}(U_{B}^{\transpose}K^{\transpose}KU_{B}),
%     \end{align*}
%     where $\sigma_{min}(\Lambda_{B})\leq \theta_{k} \leq \sigma_{max}(\Lambda_{B})$.
%     Furthermore,
%     \begin{align*}
%         \lambda_{k}(V_{B}\Lambda_{B}^{\transpose}U_{B}^{\transpose}K^{\transpose}KU_{B}\Lambda_{B}V_{B}^{\transpose}) = \lambda_{k}(\Lambda_{B}^{\transpose}U_{B}^{\transpose}K^{\transpose}KU_{B}\Lambda_{B}).
%     \end{align*}
%     Combining all the equalities above, we have that
%     \begin{align*}
%         \lambda_{k}(B^{\transpose}K^{\transpose}KB) &= \lambda_{k}(V_{B}\Lambda_{B}^{\transpose}U_{B}^{\transpose}K^{\transpose}KU_{B}\Lambda_{B}V_{B}^{\transpose})\\
%         &= \theta_{k}\lambda_{k}(U_{B}^{\transpose}K^{\transpose}KU_{B})\\
%         &= \theta_{k}\lambda_{k}(K^{\transpose}K)\\
%         &= \theta_{k}\sigma_{k}(K).
%     \end{align*}
%     Due to
%     \begin{align*}
%         \sigma_{k}(KB) &= \sigma_{k}((R+B^{\transpose}PB)^{-1}B^{\transpose}PB)\\
%         &= \sigma_{k}\bigg((I - (R+B^{\transpose}PB)^{-1}R) \bigg),
%     \end{align*}
%     and
%     \begin{align*}
%        0 < \sigma_{k}\bigg((I - (R+B^{\transpose}PB)^{-1}R) \bigg) < 1,
%     \end{align*}
%     when $P \succ 0$, we can conclude that
%     \begin{align}
%         0 < \sigma_{k}(K) < \theta_{k}
%     \end{align}
%     for $1\leq k \leq n$.
% \end{proof}

\begin{corollary}\label{corrolary:boundedK}
    Suppose the cost matrices $\{Q_{t}\}_{t=1}^{T}$ and $\{R_{t}^{i}\}_{t=1,i=1}^{T-1,2}$ satisfy the conditions described from \eqref{eq:costFPDG1} to \eqref{eq:costFPDG2}.
    For a given preview horizon $W(0\leq W \leq T-1)$, define
    \begin{equation}
        Q_{\tau|t}:= 
        \begin{cases}
            Q_{\tau} \text{ if $1\leq \tau \leq t+W$}\\
            Q_{t+w} \text{ if $t+W < \tau \leq T$},
        \end{cases}
    \end{equation}
    and
    \begin{equation}
        R_{\tau|t}^{i}:= 
        \begin{cases}
            R_{\tau}^{i} \text{ if $1\leq \tau \leq t+W$}\\
            R_{t+w}^{i} \text{ if $t+W < \tau \leq T$},
        \end{cases}
    \end{equation}
    for $i = {1,2}$.
    We further suppose matrices $\{Q_{t}\}_{t=1}^{T}$ and $\{R_{t}^{i}\}_{t=1,i=1}^{T-1,2}$ satisfy Assumption \ref{assumption:bounds}, then there exists a scalar $\omega_{K}$ such that
    \begin{equation*}
        \|K_{\tau|t}\| \leq \omega_{K},
    \end{equation*}
    for $1\leq \tau,t\leq T$.
\end{corollary}

\begin{proof}
    This can be directly concluded by letting $\omega_{K} = \sigma_{max}(B)\sigma_{max}(A)$ and applying Lemma \ref{lemma:matrixK}.
\end{proof}

\begin{assumption}\label{assumption:lowerQ}
    For any given $t(1\leq t \leq T-1)$, matrices $Q_{t}, R_{t}^{1}, \bar{R}_{t}$ satisfy
    \begin{equation}
        \lambda_{\min}(Q_{t}) > \max(0,\sigma_{max}(B)\lambda_{min}(\bar{R}_{t}-R_{t}^{1}))
    \end{equation}
    \begin{equation}
        \lambda_{min}(Q_{t}+K_{t}^{\transpose}(R_{t}^{1}-\bar{R}_{t})K_{t}) > 0.
    \end{equation}
\end{assumption}

\begin{corollary}
    For any given $\tau,t(1\leq \tau, t \leq T-1)$, matrix
    \begin{equation}
        \bar{Q}_{\tau|t} = Q_{\tau|t} + K_{\tau|t}^{\transpose}(R_{\tau|t}^{1} - \bar{R}_{\tau|t})K_{\tau|t}
    \end{equation}
    is positive definite.
\end{corollary}
\begin{proof}
    Suppose
    \begin{align*}
        &\lambda_{1}(Q_{\tau|t}) \geq \cdots \geq \lambda_{n}(Q_{\tau|t}),\\
        &\lambda_{1}(K_{\tau|t}^{\transpose}(R_{\tau|t}^{1} - \bar{R}_{\tau|t})K_{\tau|t}) \geq \cdots \geq \lambda_{n}(K_{\tau|t}^{\transpose}(R_{\tau|t}^{1} - \bar{R}_{\tau|t})K_{\tau|t}),\\
        &\lambda_{1}(R_{\tau|t}^{1} - \bar{R}_{\tau|t}) \geq \cdots \geq \lambda_{n}(R_{\tau|t}^{1} - \bar{R}_{\tau|t}).
    \end{align*}
    By Weyl's inequality,
    \begin{align*}
        \lambda_{min}(\bar{Q}_{\tau|t}) &= \lambda_{n}(\bar{Q}_{\tau|t})\\
        &\geq \lambda_{n}(Q_{\tau|t}) + \lambda_{n}(K_{\tau|t}^{\transpose}(R_{\tau|t}^{1} - \bar{R}_{\tau|t})K_{\tau|t}).
    \end{align*}
    By \cite{}[Theorem 4.5.9], there exists a positive scalar $\theta_{n}$ such that
    \begin{equation}
        \lambda_{n}(K_{\tau|t}^{\transpose}(R_{\tau|t}^{1} - \bar{R}_{\tau|t})K_{\tau|t}) = \theta_{n}\lambda_{n}(R_{\tau|t}^{1} - \bar{R}_{\tau|t}) = \theta_{n}\lambda_{min}(R_{\tau|t}^{1} - \bar{R}_{\tau|t}),
    \end{equation}
    where $\sigma_{min}(K_{\tau|t}) \leq \theta_{n} \leq \sigma_{max}(K_{\tau|t}) < \sigma_{max}(B)$.
    The last inequality is due to Lemma \ref{lemma:matrixK}. Moreover,
    \begin{align*}
        \theta_{n}\lambda_{min}(R_{\tau|t}^{1} - \bar{R}_{\tau|t}) \geq \max(0,\sigma_{B}\lambda_{min}(R_{\tau|t}^{1} - \bar{R}_{\tau|t})).
    \end{align*}
    Thus, 
    \begin{align*}
        \lambda_{min}(\bar{Q}_{\tau|t}) &= \lambda_{min}(Q_{\tau|t}+K_{t}^{\transpose}(R_{\tau|t}^{1}-\bar{R}_{\tau|t})K_{\tau|t}) \\
        &> \lambda_{min}(Q_{\tau|t}) +\max(0,\sigma_{B}\lambda_{min}(R_{\tau|t}^{1} - \bar{R}_{\tau|t})) > 0.
    \end{align*}
    Therefore, $\lambda_{min}(\bar{Q}_{\tau|t})$ is positive definite.
\end{proof}

\begin{lemma}\label{lemma:boundedP}
    Define
    \begin{equation}
        \bar{P}_{T} = \bar{Q}_{T},
    \end{equation}
    for $t = T$, and 
    \begin{equation}
    \begin{split}
        &\bar{K}_{t} = -(R_{t}+ B^{\transpose}\bar{P}_{t+1}B)^{-1}B^{\transpose}\bar{P}_{t+1},\\
        &\bar{P}_{t} = \bar{Q}_{t} + \bar{K}_{t}^{\transpose}\bar{R}_{t}\bar{K}_{t} + (A+B\bar{K}_{t})^{\transpose}\bar{P}_{t+1}(A+B\bar{K}_{t}),
    \end{split}
    \end{equation}
    for $1\leq t \leq T-1$, recursively. There exists positive definite matrices $\bar{P}_{min}$ and $\bar{P}_{max}$ such that
    \begin{equation}
        \bar{P}_{min} \preceq \bar{P}_{t} \preceq \bar{P}_{max}.
    \end{equation}
\end{lemma}
\begin{proof}
    By Corrollary \ref{corrolary:boundedK} and Assumption \ref{assumption:lowerQ}, there exists positive definite matrices $\bar{Q}_{min},\bar{Q}_{max}$ such that
    \begin{equation}
        \bar{Q}_{min} \preceq \bar{Q}_{t} \preceq \bar{Q}_{max},
    \end{equation}
    for $1\leq t \leq T$.
    Together with the Assumption \ref{assumption:bounds}, by following a similar procedure as \cite{}[???], there exists positive definite $\bar{P}_{min}$ and $\bar{P}_{max}$ such that
    \begin{equation*}
        \bar{P}_{min} \preceq \bar{P}_{t} \preceq \bar{P}_{max}.
    \end{equation*}
\end{proof}


\begin{lemma}\label{lemma:m}
    Suppose matrices $T,V_{1},V_{2},S$ are positive definite. If
    \begin{equation}
        m \geq 1+\frac{\lambda_{max}(V_{1}-V_{2})}{\lambda_{min}(T+V_{2})},
    \end{equation}
    then for any non-zero $x$, we have
    \begin{equation}
        \frac{\quadinner{T+V_{1}}}{\quadinner{S+V_{2}}} \leq m\frac{\quadinner{T+V_{2}}}{\quadinner{S+V_{2}}}
    \end{equation}
\end{lemma}
\begin{proof}
    By the assumption of $m$, for any nonzero $x$, we have
    \begin{align*}
        m &\geq 1+\frac{\lambda_{max}(V_{1}-V_{2})}{\lambda_{min}(T+V_{2})}\\
        &\geq 1+ \frac{\quadinner{V_{1}-V_{2}}}{\quadinner{T+V_{2}}}\\
        &= \frac{\quadinner{T+V_{2}}}{\quadinner{T+V_{2}}} + \frac{\quadinner{V_{1}-V_{2}}}{\quadinner{T+V_{2}}}\\
        &= \frac{\quadinner{T+V_{1}}}{\quadinner{T+V_{2}}}.
     \end{align*}
     Due to $\quadinner{S+V_{2}} > 0$ and $T,V_{2},V_{1}$ are positive definite, we have that
     \begin{align*}
         m\frac{\quadinner{T+V_{2}}}{\quadinner{S+V_{2}}} \geq \frac{\quadinner{T+V_{1}}}{\quadinner{S+V_{2}}}.
     \end{align*}
\end{proof}



% \begin{lemma}[Not sure again]
%     If the above lemma is true, we expect there exists $\bar{Q}_{min},\bar{Q}_{max}(\|\bar{Q}_{min}\|,\|\bar{Q}_{max}\|<\infty)$ that
%     \begin{equation*}
%         \bar{Q}_{min} \preceq \bar{Q}_{t} \preceq \bar{Q}_{max},
%     \end{equation*}
%     for $1\leq t \leq T$. Which
%     \begin{equation*}
%         \bar{Q}_{t} = Q_{t}+ \mathbf{K}_{t}^{\transpose}(R_{t}^{1}-\bar{R}_{t})\mathbf{K}_{t},
%     \end{equation*}
%     $\Theta_{t}$ is defined by \eqref{eq:Theta}
%     and $\mathbf{K}_{t}$ is defined by
%     \begin{equation*}
%         \mathbf{K}_{t} = -(\Theta_{t}^{-1})
%         \begin{bmatrix}
%             B^{1\transpose}P_{t+1}^{1} \\
%             B^{2\transpose}P_{t+1}^{2}
%         \end{bmatrix}A.
%     \end{equation*}
%     Which
%     \begin{equation*}
%         P_{t}^{i} = Q_{t} + \mathbf{K}_{t}^{\transpose}R_{t}^{i}\mathbf{K}_{t} + (A+\mathbf{B}\mathbf{K}_{t})^{\transpose}P_{t+1}^{i}(A+\mathbf{B}\mathbf{K}_{t}),
%     \end{equation*}
%     for $i = \{1,2\}$, $1\leq t \leq T-1$, and
%     \begin{equation*}
%         P_{T}^{i} = Q_{T},
%     \end{equation*}
%     for $i = \{1,2\}$,
%     recursively.
% \end{lemma}

\begin{definition}
    For any $X,Y\in \mathbb{S}_{++}^{n}$, define the operator $\delta_{\infty}(\cdot, \cdot)$ as
    \begin{equation*}
        \delta_{\infty}(X, Y) := \| \log(Y^{-\frac{1}{2}}XY^{-\frac{1}{2}})\|.
        % \delta_{\infty}(X, Y) := (\sum_{i=1}^{d} \log^{2}(\lambda_{i}))^{\frac{1}{2}},
    \end{equation*}
    % where $\lambda_{1},\cdots, \lambda_{d}$ are the eigenvalues of the matrix $XY^{-1}$.
\end{definition}

\begin{proposition}\label{proposition:deltaRatio}
    For any $X,Y\in \mathbb{S}_{++}^{n}$,
    \begin{equation}
        \delta_{\infty}(X,Y) = \log(\sup_{\xi\neq0} \frac{\xi^{\transpose}X\xi}{\xi^{\transpose}Y\xi}).
    \end{equation}
\end{proposition}

\begin{remark}\label{remark:delta}
    For $T,S,V_{1},V_{2}\in \mathbf{S}_{++}^{n}$. Based on Lemma \ref{lemma:boundedP},\ref{lemma:m} and Proposition \ref{proposition:deltaRatio}, suppose a positive scalar $m$ satisfy
    \begin{align*}
        m \geq 1+\frac{\lambda_{max}(V_{1}-V_{2})}{\lambda_{min}(T+V_{2})}.
    \end{align*}
    We have
    \begin{align*}
        \delta_{\infty}(T+V_{1},S+V_{2}) &= \log( \sup_{x\neq 0} \frac{\quadinner{T+V_{1}}}{\quadinner{S+V_{2}}})\\
        &\leq \log(\sup_{x\neq 0} \frac{\quadinner{T+V_{1}}}{\quadinner{S+V_{2}}})\\
        &\leq \log(m)+\log(\sup_{x\neq 0} \frac{\quadinner{T+V_{2}}}{\quadinner{S+V_{2}}})\\
        &\leq \log(m) + \delta_{\infty}(T+V_{2},S+V_{2})\\
        &\leq \log(m) + \gamma\delta_{\infty}(T,S),
    \end{align*}
    where $\gamma(0<\gamma<1)$ can be found by \cite{krauth_finite-time_2019}[Lemma D.2].
\end{remark}

\begin{lemma}\label{lemma:boundedPK}
    For any $\tau,t,t_{0}(1\leq \tau\leq t\leq t_{0}\leq T)$, suppose the preview window length is given by an non-negative integer $W(W\leq T-1)$. There exists scalars $\gamma,\varepsilon,C_{P},C_{K}(0<\gamma<1,\varepsilon>0,C_{P}>0,C_{K}>0)$, such that
    \begin{equation}
        \|\bar{P}_{\tau|t}-\bar{P}_{\tau|t_{0}}\| \leq C_{P}\gamma^{t-\tau+W}+\varepsilon_{P},
    \end{equation}
    and
    \begin{equation}
        \|\bar{K}_{\tau|t}-\bar{K}_{\tau|t_{0}}\| \leq C_{K^{'}}\gamma^{t-\tau+1+W}+\varepsilon_{K^{'}}.
    \end{equation}
\end{lemma}
\begin{proof}
     For any $\tau,t,t_{0}(1\leq \tau\leq t\leq t_{0}\leq T)$, by \cite[Lemma D.2]{krauth_finite-time_2019}, Lemma \ref{lemma:boundedP}, \ref{lemma:m} and Remark \ref{remark:delta}. 
     Let
     \begin{align*}
        &\alpha_{\tau,t} := \lambda_{max}(A^{\transpose}(\bar{P}_{\tau+1|t}^{-1}+B\bar{R}_{\tau|t}^{-1}B^{\transpose})^{-1}A)\\
        &\beta_{\tau,t} := \lambda_{min}(\bar{Q}_{\tau|t})\\ 
        &\gamma := \max_{1\leq \tau,t \leq T} \frac{\alpha_{\tau,t}}{\alpha_{\tau,t}+\beta_{\tau,t}}, 
     \end{align*}
     we have
    \begin{align*}
        \delta_{\infty}(\bar{P}_{\tau|t},\bar{P}_{\tau|t_{0}}) &= \delta_{\infty}(\bar{Q}_{\tau|t}+A^{\transpose}(\bar{P}_{\tau+1|t}^{-1}+B\bar{R}_{\tau|t}^{-1}B^{\transpose})^{-1}A,\\
        & \qquad \bar{Q}_{\tau|t_{0}}+A^{\transpose}(\bar{P}_{\tau+1|t_{0}}^{-1}+B\bar{R}_{\tau|t_{0}}^{-1}B^{\transpose})^{-1}A)\\
        % &\leq \delta_{\infty}(Q_{\tau}+K_{\tau|t}^{\transpose}(R_{\tau}^{1}-\bar{R}_{\tau})K_{\tau|t}+A^{\transpose}(P_{\tau+1|t}^{-1}+B\bar{R}_{\tau|t}^{-1}B^{\transpose})^{-1}A,\\
        % & \qquad Q_{\tau}+K_{\tau|t_{0}}^{\transpose}(R_{\tau}^{1}-\bar{R}_{\tau})K_{\tau|t_{0}}+A^{\transpose}(P_{\tau+1|t_{0}}^{-1}+B\bar{R}_{\tau|t_{0}}^{-1}B^{\transpose})^{-1}A)\\
        &\leq \gamma\delta_{\infty}(\bar{P}_{\tau+1|t},\bar{P}_{\tau+1|t_{0}}) + \varepsilon_{1}\\
        &\leq \gamma^{t-\tau+W}\delta_{\infty}(\bar{P}_{t+W|t},\bar{P}_{t+W|t_{0}}) + \varepsilon_{1}(1+\cdots+\gamma^{t-\tau-1+W})\\
        &< \gamma^{t-\tau+W}\delta_{\infty}(\bar{P}_{t+W|t},\bar{P}_{t+W|t_{0}}) + \frac{\varepsilon_{1}}{1-\gamma}\\
        &\leq C_{P1}\gamma^{t-\tau+W}+\frac{\varepsilon_{1}}{1-\gamma},
    \end{align*}
    where $\varepsilon_{1}$ can be found as similar as the term $\log(m)$ from Remark \ref{remark:delta}, and $C_{P1} = \max_{t\leq t_{0}} \delta_{\infty}(\bar{P}_{t|t},\bar{P}_{t|t_{0}})$ . By inequality
    \begin{align*}
        \frac{e^{x}-1}{x} \leq \frac{e^{c}-1}{c},
    \end{align*}
    for $0 < x \leq c$. Let $h = \max_{\{\tau,t_{0}| \tau,\leq t_{0}\}} \delta_{\infty}(\bar{P}_{\tau|t},\bar{P}_{\tau|t_{0}})$, we have
    \begin{equation}
        \frac{exp(\delta_{\infty}(\bar{P}_{\tau|t},\bar{P}_{\tau|t_{0}}))-1}{\delta_{\infty}(\bar{P}_{\tau|t},\bar{P}_{\tau|t_{0}})} \leq \frac{exp(h)-1}{h},
    \end{equation}
    then
    \begin{align*}
        \|\bar{P}_{\tau|t}-\bar{P}_{\tau|t_{0}}\| &\leq \lambda_{max}(\bar{P}_{\tau|t_{0}})\frac{\exp(h)-1}{h}\delta_{\infty}(\bar{P}_{\tau|t},\bar{P}_{\tau|t_{0}})\\
        &< C_{P}\gamma^{W}+\varepsilon_{P},
    \end{align*}
    where $C_{P} = \frac{C_{P1}\lambda_{max}(\bar{P}_{\tau|t_{0}})(\exp(h)-1)}{h}$ and $\varepsilon_{P} = \frac{\varepsilon_{1}\lambda_{max}(\bar{P}_{\tau|t_{0}})(\exp(h)-1)}{h(1-\gamma)}$. Following by similar steps of equations (20) and (21) from \cite{chen_regret_2022}[Lemma 8], we can find $C_{K^{'}},\varepsilon_{K^{'}}(C_{K^{'}}>0,\varepsilon_{K^{'}}>1)$ we have that
    \begin{align*}
        \|\bar{K}_{\tau|t}-\bar{K}_{\tau|t_{0}}\| \leq C_{K^{'}}\gamma^{t-\tau-1+W}+\varepsilon_{K^{'}}.
    \end{align*}
\end{proof}

\begin{lemma}\label{lemma:multGain}
    For time horizon $T$, suppose $1\leq t_{0} \leq t_{1}\leq t\leq T-1$. There exists scalars $C_{fb},\eta(C_{fb}>0,0<\eta<1)$ such that
    \begin{equation}
        \left \| \prod_{\tau=t_{0}}^{t_{1}}(A+\mathbf{B}\bar{K}_{\tau|t})  \right\| \leq C_{fb}\eta^{t_{1}-t_{0}+1}.
    \end{equation}
\end{lemma}
This lemma can be proved following the same steps as those found in the proof of \cite[Appendix E,Proposition 2]{zhang_regret_2021}.
\begin{lemma}
    Suppose the preview window horizon is given by a non-negative integer $W(W \leq T-1)$
    \begin{equation}
        \|x_{t}-x_{t|t}\| \leq 
    \end{equation}
\end{lemma}
\begin{proof}
    Suppose $N$ is a positive integer. For an arbitrary sequence $\{a_{i}\}_{i=1}^{N}$. Suppose $e$ is the identity element for the sequence. For $1\leq p,q\leq N$, define the product operator as
\begin{equation}
    \prod_{j=p}^{q} a_{j} := 
    \begin{cases}
        a_{q}a_{q-1}\dots a_{p} & \text{if $p < q$}\\
        a_{q} & \text{if $p = q$}\\
        e & \text{if $p > q$},
    \end{cases}
\end{equation}
Define $\omega_{t} := x_{t}-x_{t|t}$, $\theta_{\tau| p,q} := x_{\tau|p}-x_{\tau|q}$, where $\tau \leq p\leq q\leq T$. Consequently, $w_{1} = 0$ and $\theta_{1|p,q}=0$. We now investigate the dynamics of $w_{t}$ and $\theta_{\tau|p,q}$. For integer $\tau > 1$, we note that
\begin{align*}
    \theta_{\tau|p,q} &= x_{\tau|p}-x_{\tau|q}\\
    &= (A+\sum_{j}^{2}B^{j}K_{j,\tau|p})x_{\tau-1|p} - (A+\sum_{j}^{2}B^{j}K_{j,\tau|q})x_{\tau-1|q}\\
    &= (A+\sum_{j}^{2}B^{j}K_{j,\tau|p})\theta_{\tau-1|p,q} + [\sum_{j=1}^{2} B^{j}(K_{j,\tau-1|p}-K_{j,\tau-1|q})]x_{\tau-1|q}\\
    &\qquad \vdots\\
    &= \sum_{i=1}^{\tau-1}\bigg(\prod_{j=i+1}^{\tau-1}(A+\sum_{m=1}^{2}B^{m}K_{m,j|p})\bigg)\bigg[\sum_{m=1}^{2}B^{m}(K_{m,i|p}-K_{m,i|q})\bigg]x_{i|q}  \\
    &= \sum_{i=1}^{\tau-1}\bigg(\prod_{j=i+1}^{\tau-1}(A+\sum_{m=1}^{2}B^{m}K_{m,j|p})\bigg)\bigg[\sum_{m=1}^{2}B^{m}(K_{m,i|p}-K_{m,i|q})\bigg]\bigg(\prod_{n=1}^{i-1} (A+\sum_{m=1}^{2}B^{m}K_{m|q})\bigg)\bar{x}_{1}\\
    &= \sum_{i=1}^{\tau-1}\bigg(\prod_{j=i+1}^{\tau-1}(A+\mathbf{B}\bar{K}_{j|p})\bigg)\bigg[\mathbf{B}^{\mathsf{T}}(\bar{K}_{j|p}^{\mathsf{T}}-\bar{K}_{j|q}^{\mathsf{T}})\bigg]\bigg(\prod_{n=1}^{i-1} (A+\mathbf{B}\bar{K}_{n|q})\bigg)\bar{x}_{1}.
\end{align*}
Thus, for integer $t(1 < t\leq T)$, we have
\begin{align*}
    \omega_{t} = x_{t} - x_{t|t} &= Ax_{t-1} + \sum_{j=1}^{2}B^{j}[K^{j}(x_{t-1}-x_{t-1|t-1})+K_{t-1|t-1}^{j}x_{t-1|t-1}] - x_{t|t}\\
    &= (A+\sum_{j=1}^{2}B^{j}K^{j})x_{t-1} + [\sum_{j=1}^{2}B^{j}(K_{t-1|t-1}^{j}-K^{j})]x_{t-1|t-1} - x_{t|t}\\
    &= (A+\sum_{j=1}^{2}B^{j}K^{j})(x_{t-1}-x_{t-1|t-1}) + x_{t|t-1}-x_{t|t}\\
    &= \sum_{i=1}^{t} (A+\sum_{j=1}^{2}B^{j}K^{j})^{t-i} \theta_{i|i-1,i}.
\end{align*}

We now investigate the dynamics of $\theta_{\tau|p,q}$. Note that $\theta_{0|p,q} = 0$, and 

\begin{align*}
    \theta_{\tau+1|p,q} &= x_{\tau+1|p} - x_{\tau+1|q}\\
    &= (A+\BK{\tau|p})x_{\tau|p}-(A+\BK{\tau|q})x_{\tau|q}\\
    &= (A+\BK{\tau|p})(\theta_{\tau|p,q}+x_{\tau|q})-(A+\BK{\tau|q})x_{\tau|q}\\
    &= (A+\BK{\tau|p})\theta_{\tau|p,q} + \mathbf{B}(\bar{K}_{\tau|p}-\bar{K}_{\tau|q})x_{\tau|q}.
\end{align*}
This implies that
\begin{align*}
    x_{\tau+1|p} - x_{\tau+1|q} = \sum_{n=1}^{\tau}\bigg(\prod_{m=n+1}^{\tau}(A+\BK{m|p})\bigg)\mathbf{B}(\bar{K}_{n|p}-\bar{K}_{n|q})\bigg(\prod_{m=1}^{n-1}(A+\BK{m|p})\bigg)\bar{x}_{1}.
\end{align*}
By Lemma \ref{lemma:multGain}, we can bound the product term by
\begin{equation*}
    \| \prod_{m=n+1}^{\tau}(A+\BK{m|p})\| \leq C_{fb}\eta^{\tau-n},
\end{equation*}
By Lemma \ref{lemma:boundedPK}, let $C_{K} := \|\mathbf{B}\|C_{K^{'}}$ and $\varepsilon_{K} := \|\mathbf{B}\|\varepsilon_{K^{'}}$, we have
\begin{equation*}
    \|\mathbf{B}(\bar{K}_{n|p}-\bar{K}_{n|q})\| \leq C_{K}\gamma^{p-n+W}+\varepsilon_{K}.
\end{equation*}
Thus,
\begin{align*}
    \|\theta_{\tau+1|p,q}\| &= \|x_{\tau+1|p}-x_{\tau+1|q}\|\\
    &\leq C_{fb}^{2}\|\bar{x}_{1}\|(\sum_{n=1}^{\tau}\eta^{\tau}(C_{K}\gamma^{p-n}+\varepsilon_{K}))\\
    &= C_{fb}^{2}[\frac{C_{K}\gamma^{p+W}\eta^{\tau}}{1-\frac{1}{\gamma}}(1-(\frac{1}{\gamma})^{\tau+1})+ \varepsilon_{K}\tau\eta^{\tau}].
\end{align*}
Choosing $\tau = t,p = t$ and $q = T$, this results in
\begin{align*}
    \|\theta_{t|t,T}\| &\leq C^{2}_{fb}\|\bar{x}_{1}\|[\frac{C_{K}\gamma^{t+W}\eta^{t}}{1-\frac{1}{\gamma}}(1-(\frac{1}{\gamma})^{t+1}) + \varepsilon_{K}t\eta^{t}]\\
    &= C^{2}_{fb}\|\bar{x}_{1}\|[\frac{C_{K}\gamma^{1+W}\eta^{t}}{\gamma-1}(\gamma^{t}-1) + \varepsilon_{K}t\eta^{t}].
\end{align*}

Moreover,

\begin{align*}
    \|\theta_{i|i-1,i}\| \leq C_{fb}^{2}\|\bar{x}_{1}\|[\frac{C_{K}\eta^{i-1}\gamma^{W}}{\gamma-1}(\gamma^{i}-1) + \varepsilon_{K}(i-1)\eta^{i-1}].
\end{align*}
Define $\mu_{i,t} := \|(A+\mathbf{B}\bar{K})^{t-i}\|$. Conclude the above, we have
\begin{align*}
    \|x_{t}-x_{t|t}\| &\leq \sum_{\tau=1}^{t}\|(A+\mathbf{B}\bar{K})^{t-i}\theta_{i|i-1,i}\|\\
    &\leq C_{fb}^{2}\|\bar{x}_{1}\|\sum_{i=1}^{t}[\frac{C_{K}\eta^{i-1}\gamma^{W}}{\gamma-1}(\gamma^{i}-1) + \varepsilon_{K}(i-1)\eta^{i-1}]\\
    &= C_{fb}^{2}\|\bar{x}_{1}\|[\frac{C_{K}}{\gamma-1}\bigg(\frac{1-(\eta\gamma)^{t}}{1-\eta\gamma} - \frac{1-\eta^{t}}{1-\eta} \bigg)+\varepsilon_{K}\bigg(\frac{(t-1)\eta^{t+1}-t\eta^{t}+\eta}{(1-\eta)^{2}}\bigg)]
\end{align*}
% Thus,
% \begin{align*}
%     \|x_{t}-x_{t}^{*}\| \leq 
% \end{align*}

\end{proof}
\begin{theorem}
    \begin{equation}
        \text{Regret}
    \end{equation}
\end{theorem}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{NUMERICAL SIMULATIONS}

\section{CONCLUSIONS AND FUTURE WORKS}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{ACKNOWLEDGMENTS}

The authors gratefully acknowledge the contribution of National Research Organization and reviewers' comments.

\bibliographystyle{plain}
\bibliography{References}
\appendix
\end{document}


    
    
